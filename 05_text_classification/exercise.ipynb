{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e255a28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB      # 나이브 베이즈 분류 모델 (단어 빈도 기반에 적합)\n",
    "from sklearn.feature_extraction.text import CountVectorizer  # 문장을 단어 빈도 벡터로 바꿔주는 도구 (BoW)\n",
    "\n",
    "# 1. 학습에 사용할 문장 데이터 (코퍼스)\n",
    "corpus = [\"자연어 처리는 재미있다\", \"Python은 강력하다\"]\n",
    "# 각 문장에 대한 라벨 (정답)\n",
    "# 0번 문장은 0번 클래스, 1번 문장은 1번 클래스\n",
    "labels = [0, 1]\n",
    "\n",
    "# 2. 문장을 숫자 벡터로 변환 (BoW)\n",
    "vectorizer = CountVectorizer()   # 단어 등장 횟수를 세는 벡터라이저 생성\n",
    "# fit_transform:\n",
    "# 1) 단어 사전(vocabulary) 만들고  2) 각 문장을 단어 빈도 벡터로 변환\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "# 3. 나이브 베이즈 모델 생성 및 학습\n",
    "model = MultinomialNB()   # 단어 빈도에 특화된 나이브 베이즈 모델\n",
    "model.fit(X, labels)      # 벡터(X)와 정답(labels)으로 학습\n",
    "\n",
    "# 4. 새로운 문장 예측\n",
    "# 새로운 문장도 같은 방식으로 벡터로 변환해야 함\n",
    "new_X = vectorizer.transform([\"Python이 재미있다\"])\n",
    "\n",
    "# 예측 수행 (어느 클래스에 속할 확률이 높은지 판단)\n",
    "print(model.predict(new_X))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab3d15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class CNNClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, num_classes):\n",
    "        super(CNNClassifier, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
    "        self.conv = nn.Conv2d(1, 100, (3, embed_size))  # 3-gram 필터\n",
    "        self.fc = nn.Linear(100, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x).unsqueeze(1)               # 채널 추가 (B, T, E) -> (B, 1, T, E)\n",
    "        x = torch.relu(self.conv(x)).squeeze(3)\n",
    "        x = torch.max(x, dim=2)[0]                       # Max pooling\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "670fddbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.multiclass import OneVsRestClassifier  # One-Vs-Rest 래퍼 클래스(클래스별 이진분류)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# 데이터 준비\n",
    "corpus = [\"자연어 처리는 재미있다\", \"Python은 강력하다\"]\n",
    "labels = [[1, 0], [0, 1]]  # 다중 레이블\n",
    "\n",
    "# 모델 정의\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(corpus)\n",
    " # 클래스별 이진분류기를 여러개 학습해서 다중 레이블 예측하는 분류기\n",
    "model = OneVsRestClassifier(LogisticRegression())  \n",
    "model.fit(X, labels)\n",
    "\n",
    "# 예측 : 클래스별 0/1 배열\n",
    "print(model.predict(vectorizer.transform([\"Python이 재미있다\"])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
