{"cells":[{"cell_type":"markdown","id":"ff24a41d","metadata":{"id":"ff24a41d"},"source":["# BERT 전이학습\n","\n","### 데이터 준비"]},{"cell_type":"code","execution_count":1,"id":"1e880e0c","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1e880e0c","executionInfo":{"status":"ok","timestamp":1769577786772,"user_tz":-540,"elapsed":14261,"user":{"displayName":"김종민","userId":"00897423557836052337"}},"outputId":"beb0090f-2694-49a3-bfa9-d287c0b28b3e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://raw.githubusercontent.com/e9t/nsmc/master/ratings_train.txt\n","\u001b[1m14628807/14628807\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n","Downloading data from https://raw.githubusercontent.com/e9t/nsmc/master/ratings_test.txt\n","\u001b[1m4893335/4893335\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"]}],"source":["from tensorflow.keras.utils import get_file\n","\n","# NSMC (네이버 영화리뷰) 데이터 다운로드\n","ratings_train_path = get_file('ratings_train.txt', 'https://raw.githubusercontent.com/e9t/nsmc/master/ratings_train.txt')\n","ratings_test_path = get_file('ratings_test.txt', 'https://raw.githubusercontent.com/e9t/nsmc/master/ratings_test.txt')"]},{"cell_type":"code","execution_count":2,"id":"875b74b1","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":395},"id":"875b74b1","executionInfo":{"status":"ok","timestamp":1769577788642,"user_tz":-540,"elapsed":1864,"user":{"displayName":"김종민","userId":"00897423557836052337"}},"outputId":"5324d9d2-40a7-4b6a-8f6c-e025747179a8"},"outputs":[{"output_type":"display_data","data":{"text/plain":["         id                                           document  label\n","0   9976970                                아 더빙.. 진짜 짜증나네요 목소리      0\n","1   3819312                  흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나      1\n","2  10265843                                  너무재밓었다그래서보는것을추천한다      0\n","3   9045019                      교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정      0\n","4   6483659  사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...      1"],"text/html":["\n","  <div id=\"df-febafa7a-0732-4285-a577-f5e02d15bae4\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>document</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>9976970</td>\n","      <td>아 더빙.. 진짜 짜증나네요 목소리</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>3819312</td>\n","      <td>흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>10265843</td>\n","      <td>너무재밓었다그래서보는것을추천한다</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>9045019</td>\n","      <td>교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>6483659</td>\n","      <td>사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-febafa7a-0732-4285-a577-f5e02d15bae4')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-febafa7a-0732-4285-a577-f5e02d15bae4 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-febafa7a-0732-4285-a577-f5e02d15bae4');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","summary":"{\n  \"name\": \"display(ratings_test_df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2733060,\n        \"min\": 3819312,\n        \"max\": 10265843,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          3819312,\n          6483659,\n          10265843\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"document\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"\\ud760...\\ud3ec\\uc2a4\\ud130\\ubcf4\\uace0 \\ucd08\\ub529\\uc601\\ud654\\uc904....\\uc624\\ubc84\\uc5f0\\uae30\\uc870\\ucc28 \\uac00\\ubccd\\uc9c0 \\uc54a\\uad6c\\ub098\",\n          \"\\uc0ac\\uc774\\ubaac\\ud398\\uadf8\\uc758 \\uc775\\uc0b4\\uc2a4\\ub7f0 \\uc5f0\\uae30\\uac00 \\ub3cb\\ubcf4\\uc600\\ub358 \\uc601\\ud654!\\uc2a4\\ud30c\\uc774\\ub354\\ub9e8\\uc5d0\\uc11c \\ub299\\uc5b4\\ubcf4\\uc774\\uae30\\ub9cc \\ud588\\ub358 \\ucee4\\uc2a4\\ud2f4 \\ub358\\uc2a4\\ud2b8\\uac00 \\ub108\\ubb34\\ub098\\ub3c4 \\uc774\\ubed0\\ubcf4\\uc600\\ub2e4\",\n          \"\\ub108\\ubb34\\uc7ac\\ubc13\\uc5c8\\ub2e4\\uadf8\\ub798\\uc11c\\ubcf4\\ub294\\uac83\\uc744\\ucd94\\ucc9c\\ud55c\\ub2e4\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["        id                                           document  label\n","0  6270596                                                굳 ㅋ      1\n","1  9274899                               GDNTOPCLASSINTHECLUB      0\n","2  8544678             뭐야 이 평점들은.... 나쁘진 않지만 10점 짜리는 더더욱 아니잖아      0\n","3  6825595                   지루하지는 않은데 완전 막장임... 돈주고 보기에는....      0\n","4  6723715  3D만 아니었어도 별 다섯 개 줬을텐데.. 왜 3D로 나와서 제 심기를 불편하게 하죠??      0"],"text/html":["\n","  <div id=\"df-5dd5348b-cc7e-4674-ab6b-5885360be569\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>document</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>6270596</td>\n","      <td>굳 ㅋ</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>9274899</td>\n","      <td>GDNTOPCLASSINTHECLUB</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>8544678</td>\n","      <td>뭐야 이 평점들은.... 나쁘진 않지만 10점 짜리는 더더욱 아니잖아</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>6825595</td>\n","      <td>지루하지는 않은데 완전 막장임... 돈주고 보기에는....</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>6723715</td>\n","      <td>3D만 아니었어도 별 다섯 개 줬을텐데.. 왜 3D로 나와서 제 심기를 불편하게 하죠??</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5dd5348b-cc7e-4674-ab6b-5885360be569')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-5dd5348b-cc7e-4674-ab6b-5885360be569 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-5dd5348b-cc7e-4674-ab6b-5885360be569');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","summary":"{\n  \"name\": \"display(ratings_test_df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1304473,\n        \"min\": 6270596,\n        \"max\": 9274899,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          9274899,\n          6723715,\n          8544678\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"document\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"GDNTOPCLASSINTHECLUB\",\n          \"3D\\ub9cc \\uc544\\ub2c8\\uc5c8\\uc5b4\\ub3c4 \\ubcc4 \\ub2e4\\uc12f \\uac1c \\uc92c\\uc744\\ud150\\ub370.. \\uc65c 3D\\ub85c \\ub098\\uc640\\uc11c \\uc81c \\uc2ec\\uae30\\ub97c \\ubd88\\ud3b8\\ud558\\uac8c \\ud558\\uc8e0??\",\n          \"\\ubb50\\uc57c \\uc774 \\ud3c9\\uc810\\ub4e4\\uc740.... \\ub098\\uc058\\uc9c4 \\uc54a\\uc9c0\\ub9cc 10\\uc810 \\uc9dc\\ub9ac\\ub294 \\ub354\\ub354\\uc6b1 \\uc544\\ub2c8\\uc796\\uc544\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{}}],"source":["import pandas as pd\n","\n","ratings_train_df = pd.read_csv(ratings_train_path, sep='\\t')  # 학습 데이터 로드\n","ratings_test_df = pd.read_csv(ratings_test_path, sep='\\t')\n","\n","display(ratings_train_df.head())  # 상위 5개 출력\n","display(ratings_test_df.head())"]},{"cell_type":"code","execution_count":3,"id":"dc28f2f9","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":389},"id":"dc28f2f9","executionInfo":{"status":"ok","timestamp":1769577788770,"user_tz":-540,"elapsed":124,"user":{"displayName":"김종민","userId":"00897423557836052337"}},"outputId":"220d105a-321b-4bc6-bde3-5ad74143d4ef"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<bound method DataFrame.info of               id                                           document  label\n","0        9976970                                아 더빙.. 진짜 짜증나네요 목소리      0\n","1        3819312                  흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나      1\n","2       10265843                                  너무재밓었다그래서보는것을추천한다      0\n","3        9045019                      교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정      0\n","4        6483659  사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...      1\n","...          ...                                                ...    ...\n","149995   6222902                                인간이 문제지.. 소는 뭔죄인가..      0\n","149996   8549745                                      평점이 너무 낮아서...      1\n","149997   9311800                    이게 뭐요? 한국인은 거들먹거리고 필리핀 혼혈은 착하다?      0\n","149998   2376369                        청춘 영화의 최고봉.방황과 우울했던 날들의 자화상      1\n","149999   9619869                           한국 영화 최초로 수간하는 내용이 담긴 영화      0\n","\n","[149995 rows x 3 columns]>"],"text/html":["<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n","      pre.function-repr-contents {\n","        overflow-x: auto;\n","        padding: 8px 12px;\n","        max-height: 500px;\n","      }\n","\n","      pre.function-repr-contents.function-repr-contents-collapsed {\n","        cursor: pointer;\n","        max-height: 100px;\n","      }\n","    </style>\n","    <pre style=\"white-space: initial; background:\n","         var(--colab-secondary-surface-color); padding: 8px 12px;\n","         border-bottom: 1px solid var(--colab-border-color);\"><b>pandas.core.frame.DataFrame.info</b><br/>def info(verbose: bool | None=None, buf: WriteBuffer[str] | None=None, max_cols: int | None=None, memory_usage: bool | str | None=None, show_counts: bool | None=None) -&gt; None</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.12/dist-packages/pandas/core/frame.py</a>Print a concise summary of a DataFrame.\n","\n","This method prints information about a DataFrame including\n","the index dtype and columns, non-null values and memory usage.\n","\n","Parameters\n","----------\n","verbose : bool, optional\n","    Whether to print the full summary. By default, the setting in\n","    ``pandas.options.display.max_info_columns`` is followed.\n","buf : writable buffer, defaults to sys.stdout\n","    Where to send the output. By default, the output is printed to\n","    sys.stdout. Pass a writable buffer if you need to further process\n","    the output.\n","max_cols : int, optional\n","    When to switch from the verbose to the truncated output. If the\n","    DataFrame has more than `max_cols` columns, the truncated output\n","    is used. By default, the setting in\n","    ``pandas.options.display.max_info_columns`` is used.\n","memory_usage : bool, str, optional\n","    Specifies whether total memory usage of the DataFrame\n","    elements (including the index) should be displayed. By default,\n","    this follows the ``pandas.options.display.memory_usage`` setting.\n","\n","    True always show memory usage. False never shows memory usage.\n","    A value of &#x27;deep&#x27; is equivalent to &quot;True with deep introspection&quot;.\n","    Memory usage is shown in human-readable units (base-2\n","    representation). Without deep introspection a memory estimation is\n","    made based in column dtype and number of rows assuming values\n","    consume the same memory amount for corresponding dtypes. With deep\n","    memory introspection, a real memory usage calculation is performed\n","    at the cost of computational resources. See the\n","    :ref:`Frequently Asked Questions &lt;df-memory-usage&gt;` for more\n","    details.\n","show_counts : bool, optional\n","    Whether to show the non-null counts. By default, this is shown\n","    only if the DataFrame is smaller than\n","    ``pandas.options.display.max_info_rows`` and\n","    ``pandas.options.display.max_info_columns``. A value of True always\n","    shows the counts, and False never shows the counts.\n","\n","Returns\n","-------\n","None\n","    This method prints a summary of a DataFrame and returns None.\n","\n","See Also\n","--------\n","DataFrame.describe: Generate descriptive statistics of DataFrame\n","    columns.\n","DataFrame.memory_usage: Memory usage of DataFrame columns.\n","\n","Examples\n","--------\n","&gt;&gt;&gt; int_values = [1, 2, 3, 4, 5]\n","&gt;&gt;&gt; text_values = [&#x27;alpha&#x27;, &#x27;beta&#x27;, &#x27;gamma&#x27;, &#x27;delta&#x27;, &#x27;epsilon&#x27;]\n","&gt;&gt;&gt; float_values = [0.0, 0.25, 0.5, 0.75, 1.0]\n","&gt;&gt;&gt; df = pd.DataFrame({&quot;int_col&quot;: int_values, &quot;text_col&quot;: text_values,\n","...                   &quot;float_col&quot;: float_values})\n","&gt;&gt;&gt; df\n","    int_col text_col  float_col\n","0        1    alpha       0.00\n","1        2     beta       0.25\n","2        3    gamma       0.50\n","3        4    delta       0.75\n","4        5  epsilon       1.00\n","\n","Prints information of all columns:\n","\n","&gt;&gt;&gt; df.info(verbose=True)\n","&lt;class &#x27;pandas.core.frame.DataFrame&#x27;&gt;\n","RangeIndex: 5 entries, 0 to 4\n","Data columns (total 3 columns):\n"," #   Column     Non-Null Count  Dtype\n","---  ------     --------------  -----\n"," 0   int_col    5 non-null      int64\n"," 1   text_col   5 non-null      object\n"," 2   float_col  5 non-null      float64\n","dtypes: float64(1), int64(1), object(1)\n","memory usage: 248.0+ bytes\n","\n","Prints a summary of columns count and its dtypes but not per column\n","information:\n","\n","&gt;&gt;&gt; df.info(verbose=False)\n","&lt;class &#x27;pandas.core.frame.DataFrame&#x27;&gt;\n","RangeIndex: 5 entries, 0 to 4\n","Columns: 3 entries, int_col to float_col\n","dtypes: float64(1), int64(1), object(1)\n","memory usage: 248.0+ bytes\n","\n","Pipe output of DataFrame.info to buffer instead of sys.stdout, get\n","buffer content and writes to a text file:\n","\n","&gt;&gt;&gt; import io\n","&gt;&gt;&gt; buffer = io.StringIO()\n","&gt;&gt;&gt; df.info(buf=buffer)\n","&gt;&gt;&gt; s = buffer.getvalue()\n","&gt;&gt;&gt; with open(&quot;df_info.txt&quot;, &quot;w&quot;,\n","...           encoding=&quot;utf-8&quot;) as f:  # doctest: +SKIP\n","...     f.write(s)\n","260\n","\n","The `memory_usage` parameter allows deep introspection mode, specially\n","useful for big DataFrames and fine-tune memory optimization:\n","\n","&gt;&gt;&gt; random_strings_array = np.random.choice([&#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;], 10 ** 6)\n","&gt;&gt;&gt; df = pd.DataFrame({\n","...     &#x27;column_1&#x27;: np.random.choice([&#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;], 10 ** 6),\n","...     &#x27;column_2&#x27;: np.random.choice([&#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;], 10 ** 6),\n","...     &#x27;column_3&#x27;: np.random.choice([&#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;], 10 ** 6)\n","... })\n","&gt;&gt;&gt; df.info()\n","&lt;class &#x27;pandas.core.frame.DataFrame&#x27;&gt;\n","RangeIndex: 1000000 entries, 0 to 999999\n","Data columns (total 3 columns):\n"," #   Column    Non-Null Count    Dtype\n","---  ------    --------------    -----\n"," 0   column_1  1000000 non-null  object\n"," 1   column_2  1000000 non-null  object\n"," 2   column_3  1000000 non-null  object\n","dtypes: object(3)\n","memory usage: 22.9+ MB\n","\n","&gt;&gt;&gt; df.info(memory_usage=&#x27;deep&#x27;)\n","&lt;class &#x27;pandas.core.frame.DataFrame&#x27;&gt;\n","RangeIndex: 1000000 entries, 0 to 999999\n","Data columns (total 3 columns):\n"," #   Column    Non-Null Count    Dtype\n","---  ------    --------------    -----\n"," 0   column_1  1000000 non-null  object\n"," 1   column_2  1000000 non-null  object\n"," 2   column_3  1000000 non-null  object\n","dtypes: object(3)\n","memory usage: 165.9 MB</pre>\n","      <script>\n","      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n","        for (const element of document.querySelectorAll('.filepath')) {\n","          element.style.display = 'block'\n","          element.onclick = (event) => {\n","            event.preventDefault();\n","            event.stopPropagation();\n","            google.colab.files.view(element.textContent, 3646);\n","          };\n","        }\n","      }\n","      for (const element of document.querySelectorAll('.function-repr-contents')) {\n","        element.onclick = (event) => {\n","          event.preventDefault();\n","          event.stopPropagation();\n","          element.classList.toggle('function-repr-contents-collapsed');\n","        };\n","      }\n","      </script>\n","      </div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<bound method DataFrame.info of             id                                           document  label\n","0      6270596                                                굳 ㅋ      1\n","1      9274899                               GDNTOPCLASSINTHECLUB      0\n","2      8544678             뭐야 이 평점들은.... 나쁘진 않지만 10점 짜리는 더더욱 아니잖아      0\n","3      6825595                   지루하지는 않은데 완전 막장임... 돈주고 보기에는....      0\n","4      6723715  3D만 아니었어도 별 다섯 개 줬을텐데.. 왜 3D로 나와서 제 심기를 불편하게 하죠??      0\n","...        ...                                                ...    ...\n","49995  4608761          오랜만에 평점 로긴했네ㅋㅋ 킹왕짱 쌈뽕한 영화를 만났습니다 강렬하게 육쾌함      1\n","49996  5308387       의지 박약들이나 하는거다 탈영은 일단 주인공 김대희 닮았고 이등병 찐따 OOOO      0\n","49997  9072549                 그림도 좋고 완성도도 높았지만... 보는 내내 불안하게 만든다      0\n","49998  5802125     절대 봐서는 안 될 영화.. 재미도 없고 기분만 잡치고.. 한 세트장에서 다 해먹네      0\n","49999  6070594                                         마무리는 또 왜이래      0\n","\n","[49997 rows x 3 columns]>"],"text/html":["<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n","      pre.function-repr-contents {\n","        overflow-x: auto;\n","        padding: 8px 12px;\n","        max-height: 500px;\n","      }\n","\n","      pre.function-repr-contents.function-repr-contents-collapsed {\n","        cursor: pointer;\n","        max-height: 100px;\n","      }\n","    </style>\n","    <pre style=\"white-space: initial; background:\n","         var(--colab-secondary-surface-color); padding: 8px 12px;\n","         border-bottom: 1px solid var(--colab-border-color);\"><b>pandas.core.frame.DataFrame.info</b><br/>def info(verbose: bool | None=None, buf: WriteBuffer[str] | None=None, max_cols: int | None=None, memory_usage: bool | str | None=None, show_counts: bool | None=None) -&gt; None</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.12/dist-packages/pandas/core/frame.py</a>Print a concise summary of a DataFrame.\n","\n","This method prints information about a DataFrame including\n","the index dtype and columns, non-null values and memory usage.\n","\n","Parameters\n","----------\n","verbose : bool, optional\n","    Whether to print the full summary. By default, the setting in\n","    ``pandas.options.display.max_info_columns`` is followed.\n","buf : writable buffer, defaults to sys.stdout\n","    Where to send the output. By default, the output is printed to\n","    sys.stdout. Pass a writable buffer if you need to further process\n","    the output.\n","max_cols : int, optional\n","    When to switch from the verbose to the truncated output. If the\n","    DataFrame has more than `max_cols` columns, the truncated output\n","    is used. By default, the setting in\n","    ``pandas.options.display.max_info_columns`` is used.\n","memory_usage : bool, str, optional\n","    Specifies whether total memory usage of the DataFrame\n","    elements (including the index) should be displayed. By default,\n","    this follows the ``pandas.options.display.memory_usage`` setting.\n","\n","    True always show memory usage. False never shows memory usage.\n","    A value of &#x27;deep&#x27; is equivalent to &quot;True with deep introspection&quot;.\n","    Memory usage is shown in human-readable units (base-2\n","    representation). Without deep introspection a memory estimation is\n","    made based in column dtype and number of rows assuming values\n","    consume the same memory amount for corresponding dtypes. With deep\n","    memory introspection, a real memory usage calculation is performed\n","    at the cost of computational resources. See the\n","    :ref:`Frequently Asked Questions &lt;df-memory-usage&gt;` for more\n","    details.\n","show_counts : bool, optional\n","    Whether to show the non-null counts. By default, this is shown\n","    only if the DataFrame is smaller than\n","    ``pandas.options.display.max_info_rows`` and\n","    ``pandas.options.display.max_info_columns``. A value of True always\n","    shows the counts, and False never shows the counts.\n","\n","Returns\n","-------\n","None\n","    This method prints a summary of a DataFrame and returns None.\n","\n","See Also\n","--------\n","DataFrame.describe: Generate descriptive statistics of DataFrame\n","    columns.\n","DataFrame.memory_usage: Memory usage of DataFrame columns.\n","\n","Examples\n","--------\n","&gt;&gt;&gt; int_values = [1, 2, 3, 4, 5]\n","&gt;&gt;&gt; text_values = [&#x27;alpha&#x27;, &#x27;beta&#x27;, &#x27;gamma&#x27;, &#x27;delta&#x27;, &#x27;epsilon&#x27;]\n","&gt;&gt;&gt; float_values = [0.0, 0.25, 0.5, 0.75, 1.0]\n","&gt;&gt;&gt; df = pd.DataFrame({&quot;int_col&quot;: int_values, &quot;text_col&quot;: text_values,\n","...                   &quot;float_col&quot;: float_values})\n","&gt;&gt;&gt; df\n","    int_col text_col  float_col\n","0        1    alpha       0.00\n","1        2     beta       0.25\n","2        3    gamma       0.50\n","3        4    delta       0.75\n","4        5  epsilon       1.00\n","\n","Prints information of all columns:\n","\n","&gt;&gt;&gt; df.info(verbose=True)\n","&lt;class &#x27;pandas.core.frame.DataFrame&#x27;&gt;\n","RangeIndex: 5 entries, 0 to 4\n","Data columns (total 3 columns):\n"," #   Column     Non-Null Count  Dtype\n","---  ------     --------------  -----\n"," 0   int_col    5 non-null      int64\n"," 1   text_col   5 non-null      object\n"," 2   float_col  5 non-null      float64\n","dtypes: float64(1), int64(1), object(1)\n","memory usage: 248.0+ bytes\n","\n","Prints a summary of columns count and its dtypes but not per column\n","information:\n","\n","&gt;&gt;&gt; df.info(verbose=False)\n","&lt;class &#x27;pandas.core.frame.DataFrame&#x27;&gt;\n","RangeIndex: 5 entries, 0 to 4\n","Columns: 3 entries, int_col to float_col\n","dtypes: float64(1), int64(1), object(1)\n","memory usage: 248.0+ bytes\n","\n","Pipe output of DataFrame.info to buffer instead of sys.stdout, get\n","buffer content and writes to a text file:\n","\n","&gt;&gt;&gt; import io\n","&gt;&gt;&gt; buffer = io.StringIO()\n","&gt;&gt;&gt; df.info(buf=buffer)\n","&gt;&gt;&gt; s = buffer.getvalue()\n","&gt;&gt;&gt; with open(&quot;df_info.txt&quot;, &quot;w&quot;,\n","...           encoding=&quot;utf-8&quot;) as f:  # doctest: +SKIP\n","...     f.write(s)\n","260\n","\n","The `memory_usage` parameter allows deep introspection mode, specially\n","useful for big DataFrames and fine-tune memory optimization:\n","\n","&gt;&gt;&gt; random_strings_array = np.random.choice([&#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;], 10 ** 6)\n","&gt;&gt;&gt; df = pd.DataFrame({\n","...     &#x27;column_1&#x27;: np.random.choice([&#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;], 10 ** 6),\n","...     &#x27;column_2&#x27;: np.random.choice([&#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;], 10 ** 6),\n","...     &#x27;column_3&#x27;: np.random.choice([&#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;], 10 ** 6)\n","... })\n","&gt;&gt;&gt; df.info()\n","&lt;class &#x27;pandas.core.frame.DataFrame&#x27;&gt;\n","RangeIndex: 1000000 entries, 0 to 999999\n","Data columns (total 3 columns):\n"," #   Column    Non-Null Count    Dtype\n","---  ------    --------------    -----\n"," 0   column_1  1000000 non-null  object\n"," 1   column_2  1000000 non-null  object\n"," 2   column_3  1000000 non-null  object\n","dtypes: object(3)\n","memory usage: 22.9+ MB\n","\n","&gt;&gt;&gt; df.info(memory_usage=&#x27;deep&#x27;)\n","&lt;class &#x27;pandas.core.frame.DataFrame&#x27;&gt;\n","RangeIndex: 1000000 entries, 0 to 999999\n","Data columns (total 3 columns):\n"," #   Column    Non-Null Count    Dtype\n","---  ------    --------------    -----\n"," 0   column_1  1000000 non-null  object\n"," 1   column_2  1000000 non-null  object\n"," 2   column_3  1000000 non-null  object\n","dtypes: object(3)\n","memory usage: 165.9 MB</pre>\n","      <script>\n","      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n","        for (const element of document.querySelectorAll('.filepath')) {\n","          element.style.display = 'block'\n","          element.onclick = (event) => {\n","            event.preventDefault();\n","            event.stopPropagation();\n","            google.colab.files.view(element.textContent, 3646);\n","          };\n","        }\n","      }\n","      for (const element of document.querySelectorAll('.function-repr-contents')) {\n","        element.onclick = (event) => {\n","          event.preventDefault();\n","          event.stopPropagation();\n","          element.classList.toggle('function-repr-contents-collapsed');\n","        };\n","      }\n","      </script>\n","      </div>"]},"metadata":{}}],"source":["ratings_train_df = ratings_train_df.dropna(how='any')  # 학습 데이터 결측치 포함 행 제거\n","ratings_test_df = ratings_test_df.dropna(how='any')\n","\n","display(ratings_train_df.info)\n","display(ratings_test_df.info)"]},{"cell_type":"code","execution_count":4,"id":"8f1af2da","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8f1af2da","executionInfo":{"status":"ok","timestamp":1769577788821,"user_tz":-540,"elapsed":47,"user":{"displayName":"김종민","userId":"00897423557836052337"}},"outputId":"51b25453-1282-48c0-b55b-0b76d4a45f0d"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(label\n"," 0    7512\n"," 1    7488\n"," Name: count, dtype: int64,\n"," label\n"," 0    2532\n"," 1    2468\n"," Name: count, dtype: int64)"]},"metadata":{},"execution_count":4}],"source":["ratings_train_df = ratings_train_df.sample(n=15000, random_state=0)  # 학습 데이터 15000개 무작위 추출 (재현성 고정)\n","ratings_test_df = ratings_test_df.sample(n=5000, random_state=0)\n","\n","# 라벨 (0/1) 개수 분포 확인\n","ratings_train_df['label'].value_counts(), ratings_test_df['label'].value_counts()"]},{"cell_type":"code","execution_count":5,"id":"c91d721c","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c91d721c","executionInfo":{"status":"ok","timestamp":1769577788878,"user_tz":-540,"elapsed":55,"user":{"displayName":"김종민","userId":"00897423557836052337"}},"outputId":"684e8f71-d765-45ef-9960-611c2445e947"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(15000, 15000, 5000, 5000)"]},"metadata":{},"execution_count":5}],"source":["# 텍스트/라벨을 리스트로 변환 (학습/테스트 분리)\n","X_train = ratings_train_df['document'].values.tolist()  # 학습 입력 문장(document) 컬럼을 리스트로 변환\n","y_train = ratings_train_df['label'].values.tolist()\n","\n","X_test = ratings_test_df['document'].values.tolist()    # 테스트 입력 문장(document) 컬럼을 리스트로 변환\n","y_test = ratings_test_df['label'].values.tolist()\n","\n","len(X_train), len(y_train), len(X_test), len(y_test)"]},{"cell_type":"markdown","id":"f41697a3","metadata":{"id":"f41697a3"},"source":["### 토크나이저/모델 준비\n","\n","- bert 한국어 버전 사전학습 모델 klue/bert-base"]},{"cell_type":"code","execution_count":6,"id":"6ed283e6","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":209,"referenced_widgets":["95eae674f6a742ae8984699cafbfdc4f","143a5ac4bd4143dcabc5370136327f0d","74f7a4ad2fe8464b91c31045a4a2b9ef","99702a1b9f54473ba3931cb72f22575f","a0429916f9bd4cde911293bb35223148","c8ab2aacea1d411599620b5acb320d59","3ef2669d507d48b9ac86446b39f07744","b2301a4f60ab47bf96b79f0bd2b0b055","eba7ae6c69d8459baee2a4a5f0793f3c","a034bfe2b805459884c7df808318234e","74fbb7544c28465091b367cb57bb7059","f0e3c19152cc467ba0cbf6f904abd000","9c7b88ae39ac41308268f63d995668bc","3296c92fb3174243857552e5e97c0db8","3ba23c25cff4432cafddcc8457899bca","e6d755ba4f594be09c482466fab00361","42e4e807127649e89f4c8e69bd381cf7","eeb8088342334a27871c0233162187ca","f13935d4604e4bb59f84ab21332dbed9","5424e1dbfd984ff0864880a02d1c4cf6","a4b75f4ef3b649689160e7f211977696","30d613ba367e492083d8aaf75191d6c1","aa5fb192b79743089d975e44b679970b","de2a8a7a7eee4dd190e63a8f7a524ebf","41d14791b5b84ff4b15ad7af84ab8ea1","f27d699bdc1c4e6daa313c1d9be48165","461511c04a2e4a3bb4dabdbc4c120435","e7bbaad8f76c400da563ba1cc49cd427","1651552786044acab19065072b4aadf0","06139c4fb4dd482a87ebd4af74901dff","6529c5dc389342b88486de9392c906fc","fe6483045d0147d281c0f2a5ef85fd18","6dcd49643ac24abf8fa6816a7b5eba9e","c0f57058ab464a328a32578b1855f0c3","051fe901c1084d7090b07ed180470a6d","05335c9cecf24f33a9991cfcffc46bfc","495ec521516444419e16ccf8b01826c3","7684da1a15194fa2bfe9a6a5cfbfa25a","57775b9646d34560a3bcbb624a006979","b85a3b8995c64deaaa3a8b3f66cdbe6a","58e4cb27af3e4998be6f45793c203339","a475649ff16f4c2cb2868e52e3178153","26ed701823784dd482cfadb8921dddaf","cc975327dee04fc082f3c71c5c1cc532","53d4337fe38e4a97928b93da12ca5d3f","a06561dd5f1d46af84f9a7e8073ba5d8","c1ac5578ef014e139b1f270770e21ba8","3d08e83561ca47619ca93435ba11b39b","522355e460104346b61617293dd889e8","7529dd02209f4fa0a719d9b478e287db","dec2bedb2b4549e99a334191b4864d80","b5c9150a175d4b4ca52b6f1ed80612b8","c42fbc4203934449936ec790f8868870","89acf4a7df3048808e09ea9a1aa2134a","d48cb09f00c14b04986bf18e8b138644","0bfa6277f3434020909bed4e4ba9b0fa","b3d2f76a4b29485b9766e45b49e40224","9d1ece5c6e604836af68afec4fa7351b","f8c956027b034030a285b38f3c37bb36","c391bcb3eb0c469e8953fa2ec93a7528","e9cd467cc08e430b8701be9cc3dd8cff","10ef038ecb2b48df832cff5d4e759fb0","435b57bb08a446ddb4b64b6408c222b8","8a5064028feb4e84974839af5bf0db53","5e5bd5e0bdf54c47aefe9a9d95f95569","ccc8c9879f1f4d89a71f357e6852ac48"]},"id":"6ed283e6","executionInfo":{"status":"ok","timestamp":1769577844418,"user_tz":-540,"elapsed":55541,"user":{"displayName":"김종민","userId":"00897423557836052337"}},"outputId":"609300f7-f5aa-47cc-d086-709c6835afd8"},"outputs":[{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/425 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"95eae674f6a742ae8984699cafbfdc4f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/445M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f0e3c19152cc467ba0cbf6f904abd000"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/289 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aa5fb192b79743089d975e44b679970b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["vocab.txt: 0.00B [00:00, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c0f57058ab464a328a32578b1855f0c3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json: 0.00B [00:00, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"53d4337fe38e4a97928b93da12ca5d3f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0bfa6277f3434020909bed4e4ba9b0fa"}},"metadata":{}}],"source":["from transformers import AutoModel, AutoTokenizer\n","\n","model = AutoModel.from_pretrained('klue/bert-base')          # 사전학습 KLUE BERT 모델 로드 (가중치 포함)\n","tokenizer = AutoTokenizer.from_pretrained('klue/bert-base')  # 사전학습 KLUE BERT 토크나이저 로드 (토큰화 규칙/어휘)"]},{"cell_type":"code","execution_count":7,"id":"9e875802","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9e875802","executionInfo":{"status":"ok","timestamp":1769577844458,"user_tz":-540,"elapsed":40,"user":{"displayName":"김종민","userId":"00897423557836052337"}},"outputId":"a66ebe25-b41d-448c-c45b-f9de9ca6e51f"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["512"]},"metadata":{},"execution_count":7}],"source":["tokenizer.model_max_length  # 512 토큰을 넘으면 토큰화시 자름"]},{"cell_type":"code","execution_count":8,"id":"7f1f86f4","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7f1f86f4","executionInfo":{"status":"ok","timestamp":1769577848360,"user_tz":-540,"elapsed":3906,"user":{"displayName":"김종민","userId":"00897423557836052337"}},"outputId":"525c9e1f-8d46-4a24-dc88-46747924a4d1"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["([Encoding(num_tokens=142, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing]),\n","  Encoding(num_tokens=142, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing]),\n","  Encoding(num_tokens=142, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing]),\n","  Encoding(num_tokens=142, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing]),\n","  Encoding(num_tokens=142, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])],\n"," [Encoding(num_tokens=118, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing]),\n","  Encoding(num_tokens=118, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing]),\n","  Encoding(num_tokens=118, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing]),\n","  Encoding(num_tokens=118, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing]),\n","  Encoding(num_tokens=118, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])])"]},"metadata":{},"execution_count":8}],"source":["X_train = tokenizer(X_train, padding=True, truncation=True)  # 가장 긴 문장을 가진 토큰 기준으로 맞춰진다.\n","X_test = tokenizer(X_test, padding=True, truncation=True)\n","\n","X_train[:5], X_test[:5]"]},{"cell_type":"code","execution_count":9,"id":"f338a767","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f338a767","executionInfo":{"status":"ok","timestamp":1769577848386,"user_tz":-540,"elapsed":25,"user":{"displayName":"김종민","userId":"00897423557836052337"}},"outputId":"692fd7c5-98f6-4939-8392-03a865798733"},"outputs":[{"output_type":"stream","name":"stdout","text":["[2, 1800, 2178, 860, 3629, 16516, 2031, 18, 18, 18, 14242, 2205, 2062, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n","[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"]}],"source":["print(X_train['input_ids'][0])        # 토큰 -> 정수ID로 변환된 시퀀스\n","print(X_train['attention_mask'][0])   # 실제 토큰=1, 패딩=0으로 구분한 마스크\n","print(X_train['token_type_ids'][0])   # 문장 구분 ID (단일 문장은 모두 0)"]},{"cell_type":"markdown","id":"425f0711","metadata":{"id":"425f0711"},"source":["### 데이터 파이프라인 생성"]},{"cell_type":"code","execution_count":10,"id":"6f8f8d8d","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":220},"id":"6f8f8d8d","executionInfo":{"status":"ok","timestamp":1769577848546,"user_tz":-540,"elapsed":159,"user":{"displayName":"김종민","userId":"00897423557836052337"}},"outputId":"77e73ae7-1608-4656-8925-ee4dd41bd5bb"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["transformers.tokenization_utils_base.BatchEncoding"],"text/html":["<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n","      pre.function-repr-contents {\n","        overflow-x: auto;\n","        padding: 8px 12px;\n","        max-height: 500px;\n","      }\n","\n","      pre.function-repr-contents.function-repr-contents-collapsed {\n","        cursor: pointer;\n","        max-height: 100px;\n","      }\n","    </style>\n","    <pre style=\"white-space: initial; background:\n","         var(--colab-secondary-surface-color); padding: 8px 12px;\n","         border-bottom: 1px solid var(--colab-border-color);\"><b>transformers.tokenization_utils_base.BatchEncoding</b><br/>def __init__(data: Optional[dict[str, Any]]=None, encoding: Optional[Union[EncodingFast, Sequence[EncodingFast]]]=None, tensor_type: Union[None, str, TensorType]=None, prepend_batch_axis: bool=False, n_sequences: Optional[int]=None)</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.12/dist-packages/transformers/tokenization_utils_base.py</a>Holds the output of the [`~tokenization_utils_base.PreTrainedTokenizerBase.__call__`],\n","[`~tokenization_utils_base.PreTrainedTokenizerBase.encode_plus`] and\n","[`~tokenization_utils_base.PreTrainedTokenizerBase.batch_encode_plus`] methods (tokens, attention_masks, etc).\n","\n","This class is derived from a python dictionary and can be used as a dictionary. In addition, this class exposes\n","utility methods to map from word/character space to token space.\n","\n","Args:\n","    data (`dict`, *optional*):\n","        Dictionary of lists/arrays/tensors returned by the `__call__`/`encode_plus`/`batch_encode_plus` methods\n","        (&#x27;input_ids&#x27;, &#x27;attention_mask&#x27;, etc.).\n","    encoding (`tokenizers.Encoding` or `Sequence[tokenizers.Encoding]`, *optional*):\n","        If the tokenizer is a fast tokenizer which outputs additional information like mapping from word/character\n","        space to token space the `tokenizers.Encoding` instance or list of instance (for batches) hold this\n","        information.\n","    tensor_type (`Union[None, str, TensorType]`, *optional*):\n","        You can give a tensor_type here to convert the lists of integers in PyTorch/TensorFlow/Numpy Tensors at\n","        initialization.\n","    prepend_batch_axis (`bool`, *optional*, defaults to `False`):\n","        Whether or not to add a batch axis when converting to tensors (see `tensor_type` above). Note that this\n","        parameter has an effect if the parameter `tensor_type` is set, *otherwise has no effect*.\n","    n_sequences (`Optional[int]`, *optional*):\n","        You can give a tensor_type here to convert the lists of integers in PyTorch/TensorFlow/Numpy Tensors at\n","        initialization.</pre>\n","      <script>\n","      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n","        for (const element of document.querySelectorAll('.filepath')) {\n","          element.style.display = 'block'\n","          element.onclick = (event) => {\n","            event.preventDefault();\n","            event.stopPropagation();\n","            google.colab.files.view(element.textContent, 200);\n","          };\n","        }\n","      }\n","      for (const element of document.querySelectorAll('.function-repr-contents')) {\n","        element.onclick = (event) => {\n","          event.preventDefault();\n","          event.stopPropagation();\n","          element.classList.toggle('function-repr-contents-collapsed');\n","        };\n","      }\n","      </script>\n","      </div>"]},"metadata":{},"execution_count":10}],"source":["type(X_train)    # tokenizer 반환 객체 타입"]},{"cell_type":"code","execution_count":11,"id":"b4641d1d","metadata":{"id":"b4641d1d","executionInfo":{"status":"ok","timestamp":1769577888851,"user_tz":-540,"elapsed":40295,"user":{"displayName":"김종민","userId":"00897423557836052337"}}},"outputs":[],"source":["# Tensorflow 의 tf.datea.Dataset 생성 (BERT 입력 + 라벨 묶기)\n","import tensorflow as tf\n","\n","train_ds = tf.data.Dataset.from_tensor_slices((dict(X_train), y_train))  # 토큰화 dict + 라벨 = Dataset 변환 (학습용)\n","test_ds = tf.data.Dataset.from_tensor_slices((dict(X_test), y_test))     # 토큰화 dict + 라벨 = Dataset 변환 (테스트용)"]},{"cell_type":"code","execution_count":12,"id":"a46eaa47","metadata":{"id":"a46eaa47","executionInfo":{"status":"ok","timestamp":1769577888904,"user_tz":-540,"elapsed":50,"user":{"displayName":"김종민","userId":"00897423557836052337"}}},"outputs":[],"source":["# 학습 : 셔플 -> 미니배치 -> 프리배치로 파이프라인 최적화\n","train_dataset = train_ds.shuffle(10000).batch(64).prefetch(tf.data.AUTOTUNE)\n","# 테스트 : 미니배치 -> 프리배치로 파이프라인 최적화\n","test_dataset = test_ds.batch(64).prefetch(tf.data.AUTOTUNE)"]},{"cell_type":"markdown","id":"7b884a7f","metadata":{"id":"7b884a7f"},"source":[".prefetch(tf.data.AUTOTUNE) : 계산이랑 데이터 준비를 겹쳐서 미리 준비해둔다. (적당한 갯수는 Tensorflow에서 알아서 계산한다.)  \n","-> [데이터 로딩 + 모델 계산] -> [데이터 로딩 + 모델 계산]"]},{"cell_type":"code","execution_count":13,"id":"f40ce456","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":181,"referenced_widgets":["9fea164718a3430bb384d06ac660b023","2f5cceb664184ae7b290868f079bebe0","ab4e83f8f3c34ce7a14514fa9e825c2f","0319d3f36fab47bf839db3e4e9afdda8","b3b71e8c8b1744208daa998f957a8427","cad2712a88ca49ebb9837986fe4e61ce","81994b4048884193a7f815a25a2507cb","a2b6f7548ec348d2a5b0783e16079702","c6870ec2349e4d73b4f5812fde25e250","675b9e545c3e453e9b06a7dca563613a","d77b85b2a3784ee4b0549ffea383e44b"]},"id":"f40ce456","executionInfo":{"status":"ok","timestamp":1769577904291,"user_tz":-540,"elapsed":15385,"user":{"displayName":"김종민","userId":"00897423557836052337"}},"outputId":"a6c55553-b681-49c2-e6ad-a649f9e29c53"},"outputs":[{"output_type":"display_data","data":{"text/plain":["pytorch_model.bin:   0%|          | 0.00/445M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9fea164718a3430bb384d06ac660b023"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["TensorFlow and JAX classes are deprecated and will be removed in Transformers v5. We recommend migrating to PyTorch classes or pinning your version of Transformers.\n","Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertForSequenceClassification: ['bert.embeddings.position_ids']\n","- This IS expected if you are initializing TFBertForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["# KLUE BERT 분류 모델 로드\n","from transformers import TFBertForSequenceClassification\n","\n","# 2클래스 분류용 TF BERT 로드 (Pytorch 가중치 변환)\n","model = TFBertForSequenceClassification.from_pretrained('klue/bert-base', num_labels=2, from_pt=True)"]},{"cell_type":"code","execution_count":14,"id":"13c959ff","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"13c959ff","executionInfo":{"status":"ok","timestamp":1769580426143,"user_tz":-540,"elapsed":2521835,"user":{"displayName":"김종민","userId":"00897423557836052337"}},"outputId":"97f60a4b-5dd2-4719-9b11-5db3d56b8683"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/5\n","235/235 [==============================] - 526s 2s/step - loss: 0.3995 - accuracy: 0.8131 - val_loss: 0.3067 - val_accuracy: 0.8624\n","Epoch 2/5\n","235/235 [==============================] - 515s 2s/step - loss: 0.2215 - accuracy: 0.9134 - val_loss: 0.3174 - val_accuracy: 0.8696\n","Epoch 3/5\n","235/235 [==============================] - 477s 2s/step - loss: 0.1128 - accuracy: 0.9589 - val_loss: 0.4037 - val_accuracy: 0.8708\n","Epoch 4/5\n","235/235 [==============================] - 476s 2s/step - loss: 0.0506 - accuracy: 0.9831 - val_loss: 0.5023 - val_accuracy: 0.8686\n","Epoch 5/5\n","235/235 [==============================] - 476s 2s/step - loss: 0.0289 - accuracy: 0.9915 - val_loss: 0.5388 - val_accuracy: 0.8708\n"]},{"output_type":"execute_result","data":{"text/plain":["<tf_keras.src.callbacks.History at 0x7f01e0154b30>"]},"metadata":{},"execution_count":14}],"source":["# BERT 파인튜닝 설정 및 학습 (옵티마이저/컴파일/학습)\n","from transformers import create_optimizer\n","\n","num_train_steps = len(train_dataset) * 5       # 전체확습 step 수(steps_per_epoch * 5(epochs))\n","num_warmup_steps = int(num_train_steps * 0.1)  # warmup step 수(전체의 10%)\n","\n","# Transformers 권장 스케줄 포함 옵티마이저 생성\n","optimizer, _ = create_optimizer(\n","    init_lr = 5e-5,\n","    num_train_steps = num_train_steps,        # 총 학습 step 수\n","    num_warmup_steps = num_warmup_steps,      # warmup step 수\n","    weight_decay_rate = 0.1                   # weight decay 비율 (가중치 감쇠: 과적합 완화)\n",")\n","\n","# 모델 학습설정\n","model.compile(\n","    optimizer = optimizer,\n","    loss = model.hf_compute_loss,    # HF 제공 loss 계산 함수\n","    metrics = ['accuracy']\n",")\n","\n","# 모델 학습\n","model.fit(train_dataset, epochs=5,\n","            validation_data = test_dataset,\n","            batch_size=64\n",")"]},{"cell_type":"markdown","id":"24d9201c","metadata":{"id":"24d9201c"},"source":["- 워밍업(warmup) 스텝이란 학습 초반에는 학습률을 바로 크게 쓰지않고, 작은 값에서 시작해서 일정 스텝동안 점진적으로 올리는 구간\n","    - 스텝 * 0.1 => 전체 스텝에서 10%동안 LR를 천천히 올리는 설정\n","    - 동작 과정 : num_warmup_steps 동안 LR를 0 -> init_lr로 선형으로 증가시키고, 워밍업이 끝나면 LR가 점점 감소한다.\n","    - 사용 이유 : BERT 같은 사전학습 모델이 파인튜닝시에 초반에 LR가 크면 가중치가 갑자기 크게 바뀌어서 학습이 불안정/발산이 일어나 성능이 흔들릴 가능성이 있다."]},{"cell_type":"code","execution_count":15,"id":"e8374190","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e8374190","executionInfo":{"status":"ok","timestamp":1769580436839,"user_tz":-540,"elapsed":10673,"user":{"displayName":"김종민","userId":"00897423557836052337"}},"outputId":"d6d066dd-876a-4afe-d042-592c7cacf8f5"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["('nsmc_model/bert_base/tokenizer_config.json',\n"," 'nsmc_model/bert_base/special_tokens_map.json',\n"," 'nsmc_model/bert_base/vocab.txt',\n"," 'nsmc_model/bert_base/added_tokens.json',\n"," 'nsmc_model/bert_base/tokenizer.json')"]},"metadata":{},"execution_count":15}],"source":["# 파인튜닝 모델/토크나이저 저장\n","model.save_pretrained('nsmc_model/bert-base')        # 학습된 모델 가중치/설정(config) 저장\n","tokenizer.save_pretrained('nsmc_model/bert_base')    # 토크나이저 파일(vocab, tokenizer_config 등) 저장"]},{"cell_type":"markdown","id":"32872dce","metadata":{"id":"32872dce"},"source":["### 추론"]},{"cell_type":"code","execution_count":16,"id":"e660c7bd","metadata":{"id":"e660c7bd","executionInfo":{"status":"ok","timestamp":1769580436870,"user_tz":-540,"elapsed":15,"user":{"displayName":"김종민","userId":"00897423557836052337"}}},"outputs":[],"source":["# 텍스트 분류 라벨 값 지정\n","model.config.id2label = {\n","    0: \"부정\",\n","    1: \"긍정\"\n","}"]},{"cell_type":"code","execution_count":17,"id":"93be697c","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"93be697c","executionInfo":{"status":"ok","timestamp":1769580437638,"user_tz":-540,"elapsed":767,"user":{"displayName":"김종민","userId":"00897423557836052337"}},"outputId":"15bdafbd-2d56-4e8c-c9d1-895044252002"},"outputs":[{"output_type":"stream","name":"stderr","text":["TensorFlow and JAX classes are deprecated and will be removed in Transformers v5. We recommend migrating to PyTorch classes or pinning your version of Transformers.\n","Device set to use 0\n","/usr/local/lib/python3.12/dist-packages/transformers/pipelines/text_classification.py:111: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n","  warnings.warn(\n"]}],"source":["# 감성분석 파이프라인 생성\n","from transformers import TextClassificationPipeline\n","\n","# 입력 텍스트 -> 토큰화 -> 모델 추론 -> 라벨/점수 반환 파이프라인\n","sentiment_classifier = TextClassificationPipeline(\n","    tokenizer = tokenizer,      # 사용할 토크나이저\n","    model = model,              # 사용할 분류 모델\n","    framework = 'tf',           # TensorFlow 기반 모델 사용\n","    return_all_scores = True    # 모든 라벨 점수(확률/스코어) 반환\n",")"]},{"cell_type":"code","execution_count":18,"id":"2b53079a","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2b53079a","executionInfo":{"status":"ok","timestamp":1769580438203,"user_tz":-540,"elapsed":549,"user":{"displayName":"김종민","userId":"00897423557836052337"}},"outputId":"6bb84d5d-571d-4797-8256-a0b56ab56f00"},"outputs":[{"output_type":"stream","name":"stderr","text":["TensorFlow and JAX classes are deprecated and will be removed in Transformers v5. We recommend migrating to PyTorch classes or pinning your version of Transformers.\n"]},{"output_type":"execute_result","data":{"text/plain":["[[{'label': '부정', 'score': 0.0011626009363681078},\n","  {'label': '긍정', 'score': 0.998837411403656}]]"]},"metadata":{},"execution_count":18}],"source":["sentiment_classifier(\"인생 영화를 찾았습니다!!!\")  # 입력 문장에 대해 부정/긍정 점수 예측"]},{"cell_type":"markdown","id":"f7548b38","metadata":{"id":"f7548b38"},"source":["# HuggingFace\n","\n","### push"]},{"cell_type":"code","source":["from google.colab import userdata\n","\n","HF_TOKEN = userdata.get('HF_TOKEN')"],"metadata":{"id":"YX-eKojTCqIO","executionInfo":{"status":"ok","timestamp":1769580438222,"user_tz":-540,"elapsed":23,"user":{"displayName":"김종민","userId":"00897423557836052337"}}},"id":"YX-eKojTCqIO","execution_count":18,"outputs":[]},{"cell_type":"code","source":["# Hugging Face Hub에 모델/토크나이저 업로드\n","REPO_NAME = 'bert-base-nsmc'  # Hub에 생성/업로드 진행할 모델 레포지토리\n","\n","model.push_to_hub(REPO_NAME, use_auth_token=HF_TOKEN, use_temp_dir=True)       # 학습된 모델을 Hub repo로 업로드 (토큰으로 인증, 임시폴더 사용)\n","tokenizer.push_to_hub(REPO_NAME, use_auth_token=HF_TOKEN, use_temp_dir=True)   # 토크나이저 파일을 Hub repo로 업로드 (토큰으로 인증, 임시폴더 사용)"],"metadata":{"id":"86ogYJCzCqrc","executionInfo":{"status":"ok","timestamp":1769580438223,"user_tz":-540,"elapsed":1,"user":{"displayName":"김종민","userId":"00897423557836052337"}}},"id":"86ogYJCzCqrc","execution_count":18,"outputs":[]},{"cell_type":"code","source":["# Hugging Face Hub에서 업로드한 모델/토크나이저 로드\n","from transformers import AutoTokenizer, AutoModel\n","\n","REPO_NAME = 'capybaraOh/bert-base-nsmc'\n","\n","tokenizer = AutoTokenizer.from_pretrained(REPO_NAME)        # Hub repo에서 토크나이저 다운로드 후 로드\n","model = AutoModel.from_pretrained(REPO_NAME, from_tf=True)  # Hub repo에서 TF로 저장된 가중치를 읽어 AutoModel로 변환 로드"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["5373523041994ea0b2c794cc183f0080","fd5013080c9f4fdc8b0cecccec2de0c1","3ff42b4de2434f9680679dd6c4e1501a","9eff63f6e43a4a2ea95a6661186a02e1","6716368408604931a36f1d8363e711d1","b284d32b00484ff9ae0e6fad107ecc59","d891946e8aa7498c935c11c5edfefd72","495b5db0a18847c1845dd3dd7ecfb590","08b825fba84241159c56057b2b5f3268","6ce41dfdd6d94613954b5beab14b1782","300bea7de6c14ef5bbee1abc83fbbdba","1a0432b1c56b4f5b86da98810c210254","769e08a7426b418e918e3212d8eb764c","e7acc19b1740405fa4ad4651b162be79","42c04667febd45328d28ecd9d413ebe2","42b838b9674e4d919ca57bd960c7f3f1","d926f3ca7648473aa4003f3d1f1242b3","5239ffb6d044478b83b19375ad57d117","ba3d90b4bd3a4e48a77e0c7d4e10d0ea","1050aeac69604791a8639b7ba120b42a","a7902282553f44398c40deaff1c38566","c30f56b9b15a47c4aaff68086ba1f54a","105306dc3f4a4112bfa3974326f2533c","df93d22ab74b466eb83e87800f5e5bf3","278352cd4fde4cb086a77136e617d2f1","0c798595def04e3ab552b5c8ba581e48","f427c247aa57491583dc5a60123f5be4","5c2195389cdb41db89492943b18cc936","77666a82e42440538e516a09533dc1be","528dcb13a8f54f6fab7f5385c8a7db20","55be6d4570f34519a900292388edd0d2","b07558cf0bd646f2a5940b9716d555ce","caa9d75835454b7b890402574c085dfd","19ae93f24d044fb7bf6715f98771330e","f6a3babfa70e4da2947edcf02c1a7921","e9644deb434b43bc8eef9f1756f7dc54","d9754e0543ea4602846b5df42d76d7b5","9c033223237041ad887b436a0787c777","5972801a76154eae8bf55b5cb94a9878","14aefd4a370b4018b4166cdb7e848273","dbb5b4c723a5432682c9044df6756ef5","38936289ee6c4bdb95348f2af729bf65","1c4b40971908499cbc80c86b1505e8b1","b641cce6909b4e6eb5a77c0e9b0b5326","31d59d1e6b944e2b84a96e7b585f0bc2","9ffd005065ac47eda9e647b5cb05b1fd","644e5b48f37a43ea803f87b97e4cf3f7","71fd07f4f3564fd98cd29099238fd486","abbb4d3cd3974963b5172059ee9780ff","a56b914b051c432383eec68511fd8565","4ebfdf1679314fbba1d6a710e536967f","79a7ade4440b4d24ac47fcdb7faece91","fc954f001897455e97b2ff738c75def9","c4b635d1fcc54daaa52dd439d595c55b","7c8c9df6260d43c58b66e8891510c681","fbb03c6eeb4a4202be19875e43460c09","c0fbb180b39c450e8a5fd05dc8fd50c0","3807117cbc864887ad65e13c46b2317d","7786bdc8942548d9b0085f337b614153","a6fa7c9fa6854e0da7b8565811993959","80f2eb21d9b74d3cacb462bb2f54c19c","5475eff8fb8e4c859bd3571a7598d023","59349b67966b4391b5c6243d8b3b1cb1","0d561b38723b4525b30c912a697064ac","bf62c8e586044d8883591187c3351823","3c966aa3387341979dc951ec7b3bd60e"]},"id":"l3ciQIOpEUol","executionInfo":{"status":"ok","timestamp":1769581068733,"user_tz":-540,"elapsed":15440,"user":{"displayName":"김종민","userId":"00897423557836052337"}},"outputId":"a8e13272-84ec-42a4-b10a-425df0f3a70a"},"id":"l3ciQIOpEUol","execution_count":19,"outputs":[{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json: 0.00B [00:00, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5373523041994ea0b2c794cc183f0080"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["vocab.txt: 0.00B [00:00, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1a0432b1c56b4f5b86da98810c210254"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json: 0.00B [00:00, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"105306dc3f4a4112bfa3974326f2533c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["special_tokens_map.json:   0%|          | 0.00/695 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"19ae93f24d044fb7bf6715f98771330e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/645 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"31d59d1e6b944e2b84a96e7b585f0bc2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tf_model.h5:   0%|          | 0.00/443M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fbb03c6eeb4a4202be19875e43460c09"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for embeddings.word_embeddings.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for embeddings.position_embeddings.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for embeddings.token_type_embeddings.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for embeddings.LayerNorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for embeddings.LayerNorm.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.0.attention.self.query.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.0.attention.self.query.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.0.attention.self.key.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.0.attention.self.key.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.0.attention.self.value.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.0.attention.self.value.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.0.attention.output.dense.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.0.attention.output.dense.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.0.attention.output.LayerNorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.0.attention.output.LayerNorm.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.0.intermediate.dense.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.0.intermediate.dense.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.0.output.dense.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.0.output.dense.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.0.output.LayerNorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.0.output.LayerNorm.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.1.attention.self.query.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.1.attention.self.query.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.1.attention.self.key.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.1.attention.self.key.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.1.attention.self.value.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.1.attention.self.value.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.1.attention.output.dense.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.1.attention.output.dense.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.1.attention.output.LayerNorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.1.attention.output.LayerNorm.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.1.intermediate.dense.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.1.intermediate.dense.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.1.output.dense.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.1.output.dense.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.1.output.LayerNorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.1.output.LayerNorm.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.2.attention.self.query.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.2.attention.self.query.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.2.attention.self.key.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.2.attention.self.key.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.2.attention.self.value.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.2.attention.self.value.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.2.attention.output.dense.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.2.attention.output.dense.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.2.attention.output.LayerNorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.2.attention.output.LayerNorm.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.2.intermediate.dense.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.2.intermediate.dense.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.2.output.dense.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.2.output.dense.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.2.output.LayerNorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.2.output.LayerNorm.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.3.attention.self.query.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.3.attention.self.query.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.3.attention.self.key.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.3.attention.self.key.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.3.attention.self.value.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.3.attention.self.value.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.3.attention.output.dense.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.3.attention.output.dense.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.3.attention.output.LayerNorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.3.attention.output.LayerNorm.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.3.intermediate.dense.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.3.intermediate.dense.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.3.output.dense.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.3.output.dense.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.3.output.LayerNorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.3.output.LayerNorm.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.4.attention.self.query.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.4.attention.self.query.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.4.attention.self.key.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.4.attention.self.key.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.4.attention.self.value.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.4.attention.self.value.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.4.attention.output.dense.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.4.attention.output.dense.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.4.attention.output.LayerNorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.4.attention.output.LayerNorm.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.4.intermediate.dense.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.4.intermediate.dense.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.4.output.dense.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.4.output.dense.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.4.output.LayerNorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.4.output.LayerNorm.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.5.attention.self.query.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.5.attention.self.query.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.5.attention.self.key.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.5.attention.self.key.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.5.attention.self.value.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.5.attention.self.value.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.5.attention.output.dense.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.5.attention.output.dense.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.5.attention.output.LayerNorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.5.attention.output.LayerNorm.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.5.intermediate.dense.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.5.intermediate.dense.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.5.output.dense.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.5.output.dense.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.5.output.LayerNorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.5.output.LayerNorm.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.6.attention.self.query.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.6.attention.self.query.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.6.attention.self.key.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.6.attention.self.key.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.6.attention.self.value.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.6.attention.self.value.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.6.attention.output.dense.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.6.attention.output.dense.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.6.attention.output.LayerNorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.6.attention.output.LayerNorm.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.6.intermediate.dense.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.6.intermediate.dense.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.6.output.dense.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.6.output.dense.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.6.output.LayerNorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.6.output.LayerNorm.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.7.attention.self.query.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.7.attention.self.query.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.7.attention.self.key.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.7.attention.self.key.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.7.attention.self.value.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.7.attention.self.value.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.7.attention.output.dense.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.7.attention.output.dense.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.7.attention.output.LayerNorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.7.attention.output.LayerNorm.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.7.intermediate.dense.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.7.intermediate.dense.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.7.output.dense.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.7.output.dense.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.7.output.LayerNorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.7.output.LayerNorm.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.8.attention.self.query.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.8.attention.self.query.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.8.attention.self.key.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.8.attention.self.key.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.8.attention.self.value.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.8.attention.self.value.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.8.attention.output.dense.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.8.attention.output.dense.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.8.attention.output.LayerNorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.8.attention.output.LayerNorm.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.8.intermediate.dense.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.8.intermediate.dense.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.8.output.dense.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.8.output.dense.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.8.output.LayerNorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.8.output.LayerNorm.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.9.attention.self.query.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.9.attention.self.query.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.9.attention.self.key.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.9.attention.self.key.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.9.attention.self.value.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.9.attention.self.value.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.9.attention.output.dense.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.9.attention.output.dense.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.9.attention.output.LayerNorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.9.attention.output.LayerNorm.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.9.intermediate.dense.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.9.intermediate.dense.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.9.output.dense.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.9.output.dense.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.9.output.LayerNorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.9.output.LayerNorm.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.10.attention.self.query.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.10.attention.self.query.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.10.attention.self.key.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.10.attention.self.key.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.10.attention.self.value.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.10.attention.self.value.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.10.attention.output.dense.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.10.attention.output.dense.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.10.attention.output.LayerNorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.10.attention.output.LayerNorm.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.10.intermediate.dense.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.10.intermediate.dense.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.10.output.dense.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.10.output.dense.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.10.output.LayerNorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.10.output.LayerNorm.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.11.attention.self.query.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.11.attention.self.query.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.11.attention.self.key.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.11.attention.self.key.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.11.attention.self.value.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.11.attention.self.value.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.11.attention.output.dense.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.11.attention.output.dense.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.11.attention.output.LayerNorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.11.attention.output.LayerNorm.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.11.intermediate.dense.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.11.intermediate.dense.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.11.output.dense.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.11.output.dense.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.11.output.LayerNorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for encoder.layer.11.output.LayerNorm.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for pooler.dense.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:2446: UserWarning: for pooler.dense.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n","  warnings.warn(\n","All TF 2.0 model weights were used when initializing BertModel.\n","\n","All the weights of BertModel were initialized from the TF 2.0 model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use BertModel for predictions without further training.\n"]}]},{"cell_type":"code","source":["# pipeline(model='repo_id')이 내부에서 Pytorch/TF 둘다 시도 => TF만 있는 환경에서는 에러가 발생할 가능성이 높음\n","from transformers import pipeline\n","\n","sentiment_classifier = pipeline('text-classification', model=REPO_NAME)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"6UUoIxg6FyKE","executionInfo":{"status":"error","timestamp":1769581364681,"user_tz":-540,"elapsed":1875,"user":{"displayName":"김종민","userId":"00897423557836052337"}},"outputId":"7b19ffc6-45a5-4015-d875-f7e2ea2c1bdc"},"id":"6UUoIxg6FyKE","execution_count":20,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"Could not load model capybaraOh/bert-base-nsmc with any of the following classes: (<class 'transformers.models.auto.modeling_auto.AutoModelForSequenceClassification'>, <class 'transformers.models.auto.modeling_tf_auto.TFAutoModelForSequenceClassification'>, <class 'transformers.models.bert.modeling_bert.BertForSequenceClassification'>, <class 'transformers.models.bert.modeling_tf_bert.TFBertForSequenceClassification'>). See the original errors:\n\nwhile loading with AutoModelForSequenceClassification, an error is thrown:\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.12/dist-packages/transformers/pipelines/base.py\", line 293, in infer_framework_load_model\n    model = model_class.from_pretrained(model, **kwargs)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/transformers/models/auto/auto_factory.py\", line 604, in from_pretrained\n    return model_class.from_pretrained(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py\", line 277, in _wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py\", line 4900, in from_pretrained\n    checkpoint_files, sharded_metadata = _get_resolved_checkpoint_files(\n                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py\", line 1128, in _get_resolved_checkpoint_files\n    raise OSError(\nOSError: capybaraOh/bert-base-nsmc does not appear to have a file named pytorch_model.bin but there is a file for TensorFlow weights. Use `from_tf=True` to load this model from those weights.\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.12/dist-packages/transformers/pipelines/base.py\", line 311, in infer_framework_load_model\n    model = model_class.from_pretrained(model, **fp32_kwargs)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/transformers/models/auto/auto_factory.py\", line 604, in from_pretrained\n    return model_class.from_pretrained(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py\", line 277, in _wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py\", line 4900, in from_pretrained\n    checkpoint_files, sharded_metadata = _get_resolved_checkpoint_files(\n                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py\", line 1128, in _get_resolved_checkpoint_files\n    raise OSError(\nOSError: capybaraOh/bert-base-nsmc does not appear to have a file named pytorch_model.bin but there is a file for TensorFlow weights. Use `from_tf=True` to load this model from those weights.\n\nwhile loading with TFAutoModelForSequenceClassification, an error is thrown:\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.12/dist-packages/transformers/pipelines/base.py\", line 311, in infer_framework_load_model\n    model = model_class.from_pretrained(model, **fp32_kwargs)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/transformers/models/auto/auto_factory.py\", line 604, in from_pretrained\n    return model_class.from_pretrained(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/transformers/modeling_tf_utils.py\", line 2929, in from_pretrained\n    model = cls(config, *model_args, **model_kwargs)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/transformers/models/bert/modeling_tf_bert.py\", line 1700, in __init__\n    super().__init__(config, *inputs, **kwargs)\n  File \"/usr/local/lib/python3.12/dist-packages/transformers/modeling_tf_utils.py\", line 1190, in __init__\n    super().__init__(*inputs, **kwargs)\n  File \"/usr/local/lib/python3.12/dist-packages/tensorflow/python/trackable/base.py\", line 204, in _method_wrapper\n    result = method(self, *args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/tf_keras/src/utils/traceback_utils.py\", line 70, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/dtypes.py\", line 889, in as_dtype\n    raise TypeError(f\"Cannot convert the argument `type_value`: {type_value!r} \"\nTypeError: Cannot convert the argument `type_value`: torch.float32 to a TensorFlow DType.\n\nwhile loading with BertForSequenceClassification, an error is thrown:\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.12/dist-packages/transformers/pipelines/base.py\", line 293, in infer_framework_load_model\n    model = model_class.from_pretrained(model, **kwargs)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py\", line 277, in _wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py\", line 4900, in from_pretrained\n    checkpoint_files, sharded_metadata = _get_resolved_checkpoint_files(\n                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py\", line 1128, in _get_resolved_checkpoint_files\n    raise OSError(\nOSError: capybaraOh/bert-base-nsmc does not appear to have a file named pytorch_model.bin but there is a file for TensorFlow weights. Use `from_tf=True` to load this model from those weights.\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.12/dist-packages/transformers/pipelines/base.py\", line 311, in infer_framework_load_model\n    model = model_class.from_pretrained(model, **fp32_kwargs)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py\", line 277, in _wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py\", line 4900, in from_pretrained\n    checkpoint_files, sharded_metadata = _get_resolved_checkpoint_files(\n                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py\", line 1128, in _get_resolved_checkpoint_files\n    raise OSError(\nOSError: capybaraOh/bert-base-nsmc does not appear to have a file named pytorch_model.bin but there is a file for TensorFlow weights. Use `from_tf=True` to load this model from those weights.\n\nwhile loading with TFBertForSequenceClassification, an error is thrown:\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.12/dist-packages/transformers/pipelines/base.py\", line 311, in infer_framework_load_model\n    model = model_class.from_pretrained(model, **fp32_kwargs)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/transformers/modeling_tf_utils.py\", line 2929, in from_pretrained\n    model = cls(config, *model_args, **model_kwargs)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/transformers/models/bert/modeling_tf_bert.py\", line 1700, in __init__\n    super().__init__(config, *inputs, **kwargs)\n  File \"/usr/local/lib/python3.12/dist-packages/transformers/modeling_tf_utils.py\", line 1190, in __init__\n    super().__init__(*inputs, **kwargs)\n  File \"/usr/local/lib/python3.12/dist-packages/tensorflow/python/trackable/base.py\", line 204, in _method_wrapper\n    result = method(self, *args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/tf_keras/src/utils/traceback_utils.py\", line 70, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/dtypes.py\", line 889, in as_dtype\n    raise TypeError(f\"Cannot convert the argument `type_value`: {type_value!r} \"\nTypeError: Cannot convert the argument `type_value`: torch.float32 to a TensorFlow DType.\n\n\n","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-2463453773.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0msentiment_classifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'text-classification'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mREPO_NAME\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/pipelines/__init__.py\u001b[0m in \u001b[0;36mpipeline\u001b[0;34m(task, model, config, tokenizer, feature_extractor, image_processor, processor, framework, revision, use_fast, token, device, device_map, dtype, trust_remote_code, model_kwargs, pipeline_class, **kwargs)\u001b[0m\n\u001b[1;32m   1025\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mframework\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1026\u001b[0m         \u001b[0mmodel_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"tf\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtargeted_task\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"tf\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtargeted_task\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1027\u001b[0;31m         framework, model = infer_framework_load_model(\n\u001b[0m\u001b[1;32m   1028\u001b[0m             \u001b[0madapter_path\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0madapter_path\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1029\u001b[0m             \u001b[0mmodel_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_classes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/pipelines/base.py\u001b[0m in \u001b[0;36minfer_framework_load_model\u001b[0;34m(model, config, model_classes, task, framework, **model_kwargs)\u001b[0m\n\u001b[1;32m    331\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mclass_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrace\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_traceback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m                 \u001b[0merror\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34mf\"while loading with {class_name}, an error is thrown:\\n{trace}\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 333\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    334\u001b[0m                 \u001b[0;34mf\"Could not load model {model} with any of the following classes: {class_tuple}. See the original errors:\\n\\n{error}\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m             )\n","\u001b[0;31mValueError\u001b[0m: Could not load model capybaraOh/bert-base-nsmc with any of the following classes: (<class 'transformers.models.auto.modeling_auto.AutoModelForSequenceClassification'>, <class 'transformers.models.auto.modeling_tf_auto.TFAutoModelForSequenceClassification'>, <class 'transformers.models.bert.modeling_bert.BertForSequenceClassification'>, <class 'transformers.models.bert.modeling_tf_bert.TFBertForSequenceClassification'>). See the original errors:\n\nwhile loading with AutoModelForSequenceClassification, an error is thrown:\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.12/dist-packages/transformers/pipelines/base.py\", line 293, in infer_framework_load_model\n    model = model_class.from_pretrained(model, **kwargs)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/transformers/models/auto/auto_factory.py\", line 604, in from_pretrained\n    return model_class.from_pretrained(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py\", line 277, in _wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py\", line 4900, in from_pretrained\n    checkpoint_files, sharded_metadata = _get_resolved_checkpoint_files(\n                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py\", line 1128, in _get_resolved_checkpoint_files\n    raise OSError(\nOSError: capybaraOh/bert-base-nsmc does not appear to have a file named pytorch_model.bin but there is a file for TensorFlow weights. Use `from_tf=True` to load this model from those weights.\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.12/dist-packages/transformers/pipelines/base.py\", line 311, in infer_framework_load_model\n    model = model_class.from_pretrained(model, **fp32_kwargs)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/transformers/models/auto/auto_factory.py\", line 604, in from_pretrained\n    return model_class.from_pretrained(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py\", line 277, in _wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py\", line 4900, in from_pretrained\n    checkpoint_files, sharded_metadata = _get_resolved_checkpoint_files(\n                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py\", line 1128, in _get_resolved_checkpoint_files\n    raise OSError(\nOSError: capybaraOh/bert-base-nsmc does not appear to have a file named pytorch_model.bin but there is a file for TensorFlow weights. Use `from_tf=True` to load this model from those weights.\n\nwhile loading with TFAutoModelForSequenceClassification, an error is thrown:\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.12/dist-packages/transformers/pipelines/base.py\", line 311, in infer_framework_load_model\n    model = model_class.from_pretrained(model, **fp32_kwargs)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/transformers/models/auto/auto_factory.py\", line 604, in from_pretrained\n    return model_class.from_pretrained(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/transformers/modeling_tf_utils.py\", line 2929, in from_pretrained\n    model = cls(config, *model_args, **model_kwargs)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/transformers/models/bert/modeling_tf_bert.py\", line 1700, in __init__\n    super().__init__(config, *inputs, **kwargs)\n  File \"/usr/local/lib/python3.12/dist-packages/transformers/modeling_tf_utils.py\", line 1190, in __init__\n    super().__init__(*inputs, **kwargs)\n  File \"/usr/local/lib/python3.12/dist-packages/tensorflow/python/trackable/base.py\", line 204, in _method_wrapper\n    result = method(self, *args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/tf_keras/src/utils/traceback_utils.py\", line 70, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/dtypes.py\", line 889, in as_dtype\n    raise TypeError(f\"Cannot convert the argument `type_value`: {type_value!r} \"\nTypeError: Cannot convert the argument `type_value`: torch.float32 to a TensorFlow DType.\n\nwhile loading with BertForSequenceClassification, an error is thrown:\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.12/dist-packages/transformers/pipelines/base.py\", line 293, in infer_framework_load_model\n    model = model_class.from_pretrained(model, **kwargs)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py\", line 277, in _wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py\", line 4900, in from_pretrained\n    checkpoint_files, sharded_metadata = _get_resolved_checkpoint_files(\n                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py\", line 1128, in _get_resolved_checkpoint_files\n    raise OSError(\nOSError: capybaraOh/bert-base-nsmc does not appear to have a file named pytorch_model.bin but there is a file for TensorFlow weights. Use `from_tf=True` to load this model from those weights.\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.12/dist-packages/transformers/pipelines/base.py\", line 311, in infer_framework_load_model\n    model = model_class.from_pretrained(model, **fp32_kwargs)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py\", line 277, in _wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py\", line 4900, in from_pretrained\n    checkpoint_files, sharded_metadata = _get_resolved_checkpoint_files(\n                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py\", line 1128, in _get_resolved_checkpoint_files\n    raise OSError(\nOSError: capybaraOh/bert-base-nsmc does not appear to have a file named pytorch_model.bin but there is a file for TensorFlow weights. Use `from_tf=True` to load this model from those weights.\n\nwhile loading with TFBertForSequenceClassification, an error is thrown:\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.12/dist-packages/transformers/pipelines/base.py\", line 311, in infer_framework_load_model\n    model = model_class.from_pretrained(model, **fp32_kwargs)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/transformers/modeling_tf_utils.py\", line 2929, in from_pretrained\n    model = cls(config, *model_args, **model_kwargs)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/transformers/models/bert/modeling_tf_bert.py\", line 1700, in __init__\n    super().__init__(config, *inputs, **kwargs)\n  File \"/usr/local/lib/python3.12/dist-packages/transformers/modeling_tf_utils.py\", line 1190, in __init__\n    super().__init__(*inputs, **kwargs)\n  File \"/usr/local/lib/python3.12/dist-packages/tensorflow/python/trackable/base.py\", line 204, in _method_wrapper\n    result = method(self, *args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/tf_keras/src/utils/traceback_utils.py\", line 70, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/dtypes.py\", line 889, in as_dtype\n    raise TypeError(f\"Cannot convert the argument `type_value`: {type_value!r} \"\nTypeError: Cannot convert the argument `type_value`: torch.float32 to a TensorFlow DType.\n\n\n"]}]},{"cell_type":"code","source":["# pipeline 생성 + TF 분류 모델 로드 클래스\n","from transformers import pipeline, TFAutoModelForSequenceClassification\n","\n","# Hub의 TF 가중치로 분류 모델 로드\n","model = TFAutoModelForSequenceClassification.from_pretrained(REPO_NAME)\n","\n","# TF 기반 텍스트 분류 파이프라인 생성\n","sentiment_classifier = pipeline(\n","    'text-classification',    # 작업 유형 : 텍스트 분류\n","    model = model,            # 로드한 TF 분류 모델\n","    tokenizer = tokenizer,    # 로드한 토크나이저\n","    framework = 'tf'          # 프레임워크를 TF로 고정 (추론/로드시 충돌 방지)\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-rC966UMGVNx","executionInfo":{"status":"ok","timestamp":1769581375649,"user_tz":-540,"elapsed":1913,"user":{"displayName":"김종민","userId":"00897423557836052337"}},"outputId":"4464b0ac-0b08-4586-fffe-be780f4b578e"},"id":"-rC966UMGVNx","execution_count":21,"outputs":[{"output_type":"stream","name":"stderr","text":["Some layers from the model checkpoint at capybaraOh/bert-base-nsmc were not used when initializing TFBertForSequenceClassification: ['dropout_37']\n","- This IS expected if you are initializing TFBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFBertForSequenceClassification were initialized from the model checkpoint at capybaraOh/bert-base-nsmc.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForSequenceClassification for predictions without further training.\n","Device set to use 0\n"]}]},{"cell_type":"code","source":["# 감성분석 추론 실행\n","sentiment_classifier([\n","    '한국 영화는 이제 한물 갔어!',\n","    '어쩌라고 나는 재미있던데? ㅋㅋㅋ',\n","    '혜수 언니 사랑해요',\n","    '평생 잊지 못할 영화를 만났어요... 감동...'\n","])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8m6cODJ6Hs7-","executionInfo":{"status":"ok","timestamp":1769581405237,"user_tz":-540,"elapsed":2554,"user":{"displayName":"김종민","userId":"00897423557836052337"}},"outputId":"d35f820c-e431-450c-baca-0793347af2ce"},"id":"8m6cODJ6Hs7-","execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[{'label': '부정', 'score': 0.9997958540916443},\n"," {'label': '부정', 'score': 0.9954332113265991},\n"," {'label': '긍정', 'score': 0.9121177196502686},\n"," {'label': '긍정', 'score': 0.999636173248291}]"]},"metadata":{},"execution_count":22}]},{"cell_type":"code","source":[],"metadata":{"id":"UCRLQTo1RVmF"},"id":"UCRLQTo1RVmF","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.9"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"95eae674f6a742ae8984699cafbfdc4f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_143a5ac4bd4143dcabc5370136327f0d","IPY_MODEL_74f7a4ad2fe8464b91c31045a4a2b9ef","IPY_MODEL_99702a1b9f54473ba3931cb72f22575f"],"layout":"IPY_MODEL_a0429916f9bd4cde911293bb35223148"}},"143a5ac4bd4143dcabc5370136327f0d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c8ab2aacea1d411599620b5acb320d59","placeholder":"​","style":"IPY_MODEL_3ef2669d507d48b9ac86446b39f07744","value":"config.json: 100%"}},"74f7a4ad2fe8464b91c31045a4a2b9ef":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b2301a4f60ab47bf96b79f0bd2b0b055","max":425,"min":0,"orientation":"horizontal","style":"IPY_MODEL_eba7ae6c69d8459baee2a4a5f0793f3c","value":425}},"99702a1b9f54473ba3931cb72f22575f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a034bfe2b805459884c7df808318234e","placeholder":"​","style":"IPY_MODEL_74fbb7544c28465091b367cb57bb7059","value":" 425/425 [00:00&lt;00:00, 9.45kB/s]"}},"a0429916f9bd4cde911293bb35223148":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c8ab2aacea1d411599620b5acb320d59":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3ef2669d507d48b9ac86446b39f07744":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b2301a4f60ab47bf96b79f0bd2b0b055":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eba7ae6c69d8459baee2a4a5f0793f3c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a034bfe2b805459884c7df808318234e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"74fbb7544c28465091b367cb57bb7059":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f0e3c19152cc467ba0cbf6f904abd000":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9c7b88ae39ac41308268f63d995668bc","IPY_MODEL_3296c92fb3174243857552e5e97c0db8","IPY_MODEL_3ba23c25cff4432cafddcc8457899bca"],"layout":"IPY_MODEL_e6d755ba4f594be09c482466fab00361"}},"9c7b88ae39ac41308268f63d995668bc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_42e4e807127649e89f4c8e69bd381cf7","placeholder":"​","style":"IPY_MODEL_eeb8088342334a27871c0233162187ca","value":"model.safetensors: 100%"}},"3296c92fb3174243857552e5e97c0db8":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f13935d4604e4bb59f84ab21332dbed9","max":445000316,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5424e1dbfd984ff0864880a02d1c4cf6","value":445000316}},"3ba23c25cff4432cafddcc8457899bca":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a4b75f4ef3b649689160e7f211977696","placeholder":"​","style":"IPY_MODEL_30d613ba367e492083d8aaf75191d6c1","value":" 445M/445M [00:09&lt;00:00, 35.0MB/s]"}},"e6d755ba4f594be09c482466fab00361":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"42e4e807127649e89f4c8e69bd381cf7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eeb8088342334a27871c0233162187ca":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f13935d4604e4bb59f84ab21332dbed9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5424e1dbfd984ff0864880a02d1c4cf6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a4b75f4ef3b649689160e7f211977696":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"30d613ba367e492083d8aaf75191d6c1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"aa5fb192b79743089d975e44b679970b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_de2a8a7a7eee4dd190e63a8f7a524ebf","IPY_MODEL_41d14791b5b84ff4b15ad7af84ab8ea1","IPY_MODEL_f27d699bdc1c4e6daa313c1d9be48165"],"layout":"IPY_MODEL_461511c04a2e4a3bb4dabdbc4c120435"}},"de2a8a7a7eee4dd190e63a8f7a524ebf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e7bbaad8f76c400da563ba1cc49cd427","placeholder":"​","style":"IPY_MODEL_1651552786044acab19065072b4aadf0","value":"tokenizer_config.json: 100%"}},"41d14791b5b84ff4b15ad7af84ab8ea1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_06139c4fb4dd482a87ebd4af74901dff","max":289,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6529c5dc389342b88486de9392c906fc","value":289}},"f27d699bdc1c4e6daa313c1d9be48165":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fe6483045d0147d281c0f2a5ef85fd18","placeholder":"​","style":"IPY_MODEL_6dcd49643ac24abf8fa6816a7b5eba9e","value":" 289/289 [00:00&lt;00:00, 10.4kB/s]"}},"461511c04a2e4a3bb4dabdbc4c120435":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e7bbaad8f76c400da563ba1cc49cd427":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1651552786044acab19065072b4aadf0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"06139c4fb4dd482a87ebd4af74901dff":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6529c5dc389342b88486de9392c906fc":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"fe6483045d0147d281c0f2a5ef85fd18":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6dcd49643ac24abf8fa6816a7b5eba9e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c0f57058ab464a328a32578b1855f0c3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_051fe901c1084d7090b07ed180470a6d","IPY_MODEL_05335c9cecf24f33a9991cfcffc46bfc","IPY_MODEL_495ec521516444419e16ccf8b01826c3"],"layout":"IPY_MODEL_7684da1a15194fa2bfe9a6a5cfbfa25a"}},"051fe901c1084d7090b07ed180470a6d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_57775b9646d34560a3bcbb624a006979","placeholder":"​","style":"IPY_MODEL_b85a3b8995c64deaaa3a8b3f66cdbe6a","value":"vocab.txt: "}},"05335c9cecf24f33a9991cfcffc46bfc":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_58e4cb27af3e4998be6f45793c203339","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a475649ff16f4c2cb2868e52e3178153","value":1}},"495ec521516444419e16ccf8b01826c3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_26ed701823784dd482cfadb8921dddaf","placeholder":"​","style":"IPY_MODEL_cc975327dee04fc082f3c71c5c1cc532","value":" 248k/? [00:00&lt;00:00, 3.73MB/s]"}},"7684da1a15194fa2bfe9a6a5cfbfa25a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"57775b9646d34560a3bcbb624a006979":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b85a3b8995c64deaaa3a8b3f66cdbe6a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"58e4cb27af3e4998be6f45793c203339":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"a475649ff16f4c2cb2868e52e3178153":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"26ed701823784dd482cfadb8921dddaf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cc975327dee04fc082f3c71c5c1cc532":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"53d4337fe38e4a97928b93da12ca5d3f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a06561dd5f1d46af84f9a7e8073ba5d8","IPY_MODEL_c1ac5578ef014e139b1f270770e21ba8","IPY_MODEL_3d08e83561ca47619ca93435ba11b39b"],"layout":"IPY_MODEL_522355e460104346b61617293dd889e8"}},"a06561dd5f1d46af84f9a7e8073ba5d8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7529dd02209f4fa0a719d9b478e287db","placeholder":"​","style":"IPY_MODEL_dec2bedb2b4549e99a334191b4864d80","value":"tokenizer.json: "}},"c1ac5578ef014e139b1f270770e21ba8":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b5c9150a175d4b4ca52b6f1ed80612b8","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c42fbc4203934449936ec790f8868870","value":1}},"3d08e83561ca47619ca93435ba11b39b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_89acf4a7df3048808e09ea9a1aa2134a","placeholder":"​","style":"IPY_MODEL_d48cb09f00c14b04986bf18e8b138644","value":" 495k/? [00:00&lt;00:00, 7.03MB/s]"}},"522355e460104346b61617293dd889e8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7529dd02209f4fa0a719d9b478e287db":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dec2bedb2b4549e99a334191b4864d80":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b5c9150a175d4b4ca52b6f1ed80612b8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"c42fbc4203934449936ec790f8868870":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"89acf4a7df3048808e09ea9a1aa2134a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d48cb09f00c14b04986bf18e8b138644":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0bfa6277f3434020909bed4e4ba9b0fa":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b3d2f76a4b29485b9766e45b49e40224","IPY_MODEL_9d1ece5c6e604836af68afec4fa7351b","IPY_MODEL_f8c956027b034030a285b38f3c37bb36"],"layout":"IPY_MODEL_c391bcb3eb0c469e8953fa2ec93a7528"}},"b3d2f76a4b29485b9766e45b49e40224":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e9cd467cc08e430b8701be9cc3dd8cff","placeholder":"​","style":"IPY_MODEL_10ef038ecb2b48df832cff5d4e759fb0","value":"special_tokens_map.json: 100%"}},"9d1ece5c6e604836af68afec4fa7351b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_435b57bb08a446ddb4b64b6408c222b8","max":125,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8a5064028feb4e84974839af5bf0db53","value":125}},"f8c956027b034030a285b38f3c37bb36":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5e5bd5e0bdf54c47aefe9a9d95f95569","placeholder":"​","style":"IPY_MODEL_ccc8c9879f1f4d89a71f357e6852ac48","value":" 125/125 [00:00&lt;00:00, 3.75kB/s]"}},"c391bcb3eb0c469e8953fa2ec93a7528":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e9cd467cc08e430b8701be9cc3dd8cff":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"10ef038ecb2b48df832cff5d4e759fb0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"435b57bb08a446ddb4b64b6408c222b8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8a5064028feb4e84974839af5bf0db53":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5e5bd5e0bdf54c47aefe9a9d95f95569":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ccc8c9879f1f4d89a71f357e6852ac48":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9fea164718a3430bb384d06ac660b023":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2f5cceb664184ae7b290868f079bebe0","IPY_MODEL_ab4e83f8f3c34ce7a14514fa9e825c2f","IPY_MODEL_0319d3f36fab47bf839db3e4e9afdda8"],"layout":"IPY_MODEL_b3b71e8c8b1744208daa998f957a8427"}},"2f5cceb664184ae7b290868f079bebe0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cad2712a88ca49ebb9837986fe4e61ce","placeholder":"​","style":"IPY_MODEL_81994b4048884193a7f815a25a2507cb","value":"pytorch_model.bin: 100%"}},"ab4e83f8f3c34ce7a14514fa9e825c2f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a2b6f7548ec348d2a5b0783e16079702","max":445025130,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c6870ec2349e4d73b4f5812fde25e250","value":445025130}},"0319d3f36fab47bf839db3e4e9afdda8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_675b9e545c3e453e9b06a7dca563613a","placeholder":"​","style":"IPY_MODEL_d77b85b2a3784ee4b0549ffea383e44b","value":" 445M/445M [00:05&lt;00:00, 125MB/s]"}},"b3b71e8c8b1744208daa998f957a8427":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cad2712a88ca49ebb9837986fe4e61ce":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"81994b4048884193a7f815a25a2507cb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a2b6f7548ec348d2a5b0783e16079702":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c6870ec2349e4d73b4f5812fde25e250":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"675b9e545c3e453e9b06a7dca563613a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d77b85b2a3784ee4b0549ffea383e44b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5373523041994ea0b2c794cc183f0080":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fd5013080c9f4fdc8b0cecccec2de0c1","IPY_MODEL_3ff42b4de2434f9680679dd6c4e1501a","IPY_MODEL_9eff63f6e43a4a2ea95a6661186a02e1"],"layout":"IPY_MODEL_6716368408604931a36f1d8363e711d1"}},"fd5013080c9f4fdc8b0cecccec2de0c1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b284d32b00484ff9ae0e6fad107ecc59","placeholder":"​","style":"IPY_MODEL_d891946e8aa7498c935c11c5edfefd72","value":"tokenizer_config.json: "}},"3ff42b4de2434f9680679dd6c4e1501a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_495b5db0a18847c1845dd3dd7ecfb590","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_08b825fba84241159c56057b2b5f3268","value":1}},"9eff63f6e43a4a2ea95a6661186a02e1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6ce41dfdd6d94613954b5beab14b1782","placeholder":"​","style":"IPY_MODEL_300bea7de6c14ef5bbee1abc83fbbdba","value":" 1.27k/? [00:00&lt;00:00, 34.0kB/s]"}},"6716368408604931a36f1d8363e711d1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b284d32b00484ff9ae0e6fad107ecc59":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d891946e8aa7498c935c11c5edfefd72":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"495b5db0a18847c1845dd3dd7ecfb590":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"08b825fba84241159c56057b2b5f3268":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6ce41dfdd6d94613954b5beab14b1782":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"300bea7de6c14ef5bbee1abc83fbbdba":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1a0432b1c56b4f5b86da98810c210254":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_769e08a7426b418e918e3212d8eb764c","IPY_MODEL_e7acc19b1740405fa4ad4651b162be79","IPY_MODEL_42c04667febd45328d28ecd9d413ebe2"],"layout":"IPY_MODEL_42b838b9674e4d919ca57bd960c7f3f1"}},"769e08a7426b418e918e3212d8eb764c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d926f3ca7648473aa4003f3d1f1242b3","placeholder":"​","style":"IPY_MODEL_5239ffb6d044478b83b19375ad57d117","value":"vocab.txt: "}},"e7acc19b1740405fa4ad4651b162be79":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ba3d90b4bd3a4e48a77e0c7d4e10d0ea","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1050aeac69604791a8639b7ba120b42a","value":1}},"42c04667febd45328d28ecd9d413ebe2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a7902282553f44398c40deaff1c38566","placeholder":"​","style":"IPY_MODEL_c30f56b9b15a47c4aaff68086ba1f54a","value":" 248k/? [00:00&lt;00:00, 7.30MB/s]"}},"42b838b9674e4d919ca57bd960c7f3f1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d926f3ca7648473aa4003f3d1f1242b3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5239ffb6d044478b83b19375ad57d117":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ba3d90b4bd3a4e48a77e0c7d4e10d0ea":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"1050aeac69604791a8639b7ba120b42a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a7902282553f44398c40deaff1c38566":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c30f56b9b15a47c4aaff68086ba1f54a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"105306dc3f4a4112bfa3974326f2533c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_df93d22ab74b466eb83e87800f5e5bf3","IPY_MODEL_278352cd4fde4cb086a77136e617d2f1","IPY_MODEL_0c798595def04e3ab552b5c8ba581e48"],"layout":"IPY_MODEL_f427c247aa57491583dc5a60123f5be4"}},"df93d22ab74b466eb83e87800f5e5bf3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5c2195389cdb41db89492943b18cc936","placeholder":"​","style":"IPY_MODEL_77666a82e42440538e516a09533dc1be","value":"tokenizer.json: "}},"278352cd4fde4cb086a77136e617d2f1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_528dcb13a8f54f6fab7f5385c8a7db20","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_55be6d4570f34519a900292388edd0d2","value":1}},"0c798595def04e3ab552b5c8ba581e48":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b07558cf0bd646f2a5940b9716d555ce","placeholder":"​","style":"IPY_MODEL_caa9d75835454b7b890402574c085dfd","value":" 752k/? [00:00&lt;00:00, 10.7MB/s]"}},"f427c247aa57491583dc5a60123f5be4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5c2195389cdb41db89492943b18cc936":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"77666a82e42440538e516a09533dc1be":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"528dcb13a8f54f6fab7f5385c8a7db20":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"55be6d4570f34519a900292388edd0d2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b07558cf0bd646f2a5940b9716d555ce":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"caa9d75835454b7b890402574c085dfd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"19ae93f24d044fb7bf6715f98771330e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f6a3babfa70e4da2947edcf02c1a7921","IPY_MODEL_e9644deb434b43bc8eef9f1756f7dc54","IPY_MODEL_d9754e0543ea4602846b5df42d76d7b5"],"layout":"IPY_MODEL_9c033223237041ad887b436a0787c777"}},"f6a3babfa70e4da2947edcf02c1a7921":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5972801a76154eae8bf55b5cb94a9878","placeholder":"​","style":"IPY_MODEL_14aefd4a370b4018b4166cdb7e848273","value":"special_tokens_map.json: 100%"}},"e9644deb434b43bc8eef9f1756f7dc54":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_dbb5b4c723a5432682c9044df6756ef5","max":695,"min":0,"orientation":"horizontal","style":"IPY_MODEL_38936289ee6c4bdb95348f2af729bf65","value":695}},"d9754e0543ea4602846b5df42d76d7b5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1c4b40971908499cbc80c86b1505e8b1","placeholder":"​","style":"IPY_MODEL_b641cce6909b4e6eb5a77c0e9b0b5326","value":" 695/695 [00:00&lt;00:00, 21.3kB/s]"}},"9c033223237041ad887b436a0787c777":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5972801a76154eae8bf55b5cb94a9878":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"14aefd4a370b4018b4166cdb7e848273":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"dbb5b4c723a5432682c9044df6756ef5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"38936289ee6c4bdb95348f2af729bf65":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1c4b40971908499cbc80c86b1505e8b1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b641cce6909b4e6eb5a77c0e9b0b5326":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"31d59d1e6b944e2b84a96e7b585f0bc2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9ffd005065ac47eda9e647b5cb05b1fd","IPY_MODEL_644e5b48f37a43ea803f87b97e4cf3f7","IPY_MODEL_71fd07f4f3564fd98cd29099238fd486"],"layout":"IPY_MODEL_abbb4d3cd3974963b5172059ee9780ff"}},"9ffd005065ac47eda9e647b5cb05b1fd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a56b914b051c432383eec68511fd8565","placeholder":"​","style":"IPY_MODEL_4ebfdf1679314fbba1d6a710e536967f","value":"config.json: 100%"}},"644e5b48f37a43ea803f87b97e4cf3f7":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_79a7ade4440b4d24ac47fcdb7faece91","max":645,"min":0,"orientation":"horizontal","style":"IPY_MODEL_fc954f001897455e97b2ff738c75def9","value":645}},"71fd07f4f3564fd98cd29099238fd486":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c4b635d1fcc54daaa52dd439d595c55b","placeholder":"​","style":"IPY_MODEL_7c8c9df6260d43c58b66e8891510c681","value":" 645/645 [00:00&lt;00:00, 21.9kB/s]"}},"abbb4d3cd3974963b5172059ee9780ff":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a56b914b051c432383eec68511fd8565":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4ebfdf1679314fbba1d6a710e536967f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"79a7ade4440b4d24ac47fcdb7faece91":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fc954f001897455e97b2ff738c75def9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c4b635d1fcc54daaa52dd439d595c55b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7c8c9df6260d43c58b66e8891510c681":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fbb03c6eeb4a4202be19875e43460c09":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c0fbb180b39c450e8a5fd05dc8fd50c0","IPY_MODEL_3807117cbc864887ad65e13c46b2317d","IPY_MODEL_7786bdc8942548d9b0085f337b614153"],"layout":"IPY_MODEL_a6fa7c9fa6854e0da7b8565811993959"}},"c0fbb180b39c450e8a5fd05dc8fd50c0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_80f2eb21d9b74d3cacb462bb2f54c19c","placeholder":"​","style":"IPY_MODEL_5475eff8fb8e4c859bd3571a7598d023","value":"tf_model.h5: 100%"}},"3807117cbc864887ad65e13c46b2317d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_59349b67966b4391b5c6243d8b3b1cb1","max":442763544,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0d561b38723b4525b30c912a697064ac","value":442763544}},"7786bdc8942548d9b0085f337b614153":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bf62c8e586044d8883591187c3351823","placeholder":"​","style":"IPY_MODEL_3c966aa3387341979dc951ec7b3bd60e","value":" 443M/443M [00:05&lt;00:00, 158MB/s]"}},"a6fa7c9fa6854e0da7b8565811993959":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"80f2eb21d9b74d3cacb462bb2f54c19c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5475eff8fb8e4c859bd3571a7598d023":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"59349b67966b4391b5c6243d8b3b1cb1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0d561b38723b4525b30c912a697064ac":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"bf62c8e586044d8883591187c3351823":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3c966aa3387341979dc951ec7b3bd60e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":5}