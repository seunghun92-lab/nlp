{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ueBwA9VrXKlA"
   },
   "source": [
    "# BERT Overview\n",
    "\n",
    "\n",
    "BERT(Bidirectional Encoder Representations from Transformers)는 Google에서 개발한 자연어 처리 모델이다. 트랜스포머(Transformer) 구조를 기반으로 하며, 텍스트의 전후 관계를 동시에 고려하여 문맥을 이해하는 데 강점이 있다. 트랜스포머는 **Self-Attention 메커니즘**을 활용해 입력 문장 내 모든 단어 간의 연관성을 계산한다.\n",
    "\n",
    "기존 NLP 모델들은 주로 단방향(왼쪽에서 오른쪽 또는 오른쪽에서 왼쪽)의 문맥만을 학습했지만, BERT는 양방향성을 통해 문장의 의미를 더 깊이 이해할 수 있다.\n",
    "\n",
    "![](https://d.pr/i/okegVU+)\n",
    "\n",
    "![](https://d.pr/i/bWZKkU+)\n",
    "\n",
    "**1. BERT의 핵심 특징**\n",
    "- **양방향성(Bidirectionality):** 양방향 Transformer Encoder를 사용하여 입력 데이터의 전후 맥락을 동시에 학습한다.\n",
    "- **사전학습(Pre-training)과 미세조정(Fine-tuning):** 대규모 코퍼스에서 사전학습한 후, 특정 작업에 맞게 미세조정 가능하다.\n",
    "- **전이학습(Transfer Learning):** 사전학습된 모델을 다양한 NLP 작업에 재사용하여 높은 성능을 얻는다.\n",
    "- **Masked Language Model (MLM):** 입력 토큰의 일부를 마스킹하고 이를 예측하는 방법으로 학습한다.\n",
    "- **Next Sentence Prediction (NSP):** 두 문장이 연속적인 문장인지 여부를 예측하도록 학습한다.\n",
    "\n",
    "**2. BERT 입력 표현 방식**\n",
    "\n",
    "![](https://d.pr/i/HW063x+)\n",
    "\n",
    "BERT는 입력 문장을 다음 세 가지 임베딩의 합으로 표현한다.\n",
    "- **Token Embedding**: WordPiece 토크나이저로 분할된 각 토큰의 임베딩. 자주 등장하는 단어는 그대로, 드물거나 긴 단어는 sub-word 단위로 분할하여 OOV(Out-Of-Vocabulary) 문제를 해결한다.\n",
    "- **Segment Embedding**: 문장 구분 임베딩. 두 문장이 입력될 경우 첫 번째 문장은 0, 두 번째 문장은 1로 구분한다.\n",
    "- **Position Embedding**: 각 토큰의 순서 정보를 담는 임베딩. 트랜스포머 구조가 순서 정보를 직접 반영하지 못하기 때문에 추가된다.\n",
    "- 토큰 설명\n",
    "  1. **[CLS] 토큰:** 문장의 시작을 나타내는 특별 토큰으로, 분류 작업에서 문장 전체의 표현으로 사용된다.\n",
    "  2. **[SEP] 토큰:** 문장 또는 문장 쌍을 구분하는 역할을 한다.\n",
    "\n",
    "\n",
    "**3. BERT의 사전학습 방법**\n",
    "\n",
    "1. **Masked Language Model (MLM):**\n",
    "   - 입력 문장의 일부 토큰을 `[MASK]`로 대체한다.\n",
    "   - 모델은 해당 마스크된 단어를 예측하는 작업을 통해 단어 간의 문맥을 학습한다.\n",
    "   - 예시:  \n",
    "     입력: \"The cat sat on the [MASK].\"  \n",
    "     출력: \"mat\"\n",
    "   \n",
    "2. **Next Sentence Prediction (NSP):**\n",
    "   - 두 문장을 입력으로 받아 두 문장이 실제로 연속적인 문장인지 예측한다.\n",
    "   - 예시:\n",
    "     - 문장 A: \"I love programming.\"\n",
    "     - 문장 B: \"It is very satisfying.\"\n",
    "     - 예측: True\n",
    "\n",
    "**4. BERT의 주요 사용 사례**\n",
    "- **텍스트 분류:** 감성 분석, 주제 분류 등\n",
    "- **문장 유사도:** 질문과 답변 매칭, 검색 엔진 최적화\n",
    "- **문장 생성 및 완성:** 자연어 생성, 채팅봇\n",
    "- **Named Entity Recognition (NER):** 텍스트에서 개체(인물, 장소, 조직 등) 추출\n",
    "- **기계 번역:** 언어 간 텍스트 변환\n",
    "- **질의응답 시스템(QA):** 문맥 기반 질문에 대한 답변 생성\n",
    "\n",
    "**5. BERT 모델 구조**\n",
    "\n",
    "| 모델명      | 인코더 레이어 수(L) | 히든 차원(H) | 어텐션 헤드 수(A) | 파라미터 수      |\n",
    "|-------------|---------------------|--------------|-------------------|------------------|\n",
    "| BERT-base   | 12                  | 768          | 12                | 약 1억 1천만 개  |\n",
    "| BERT-large  | 24                  | 1024         | 16                | 약 3억 4천만 개  |\n",
    "\n",
    "- **BERT-base**: L=12, H=768, A=12, 110M 파라미터\n",
    "- **BERT-large**: L=24, H=1024, A=16, 340M 파라미터\n",
    "\n",
    "![https://www.weak-learner.com/blog/2019/08/16/bert/](https://d.pr/i/tGS8uA+)\n",
    "\n",
    "- **입력 임베딩:** 토큰, 세그먼트, 포지션 임베딩의 합\n",
    "- **Transformer Encoder Layers:**\n",
    "  - 총 12층(BERT Base) 또는 24층(BERT Large)으로 구성\n",
    "  - 각 층은 Multi-head Attention과 Feedforward Neural Network로 이루어짐\n",
    "- **출력:**\n",
    "  - `[CLS]`의 출력은 전체 문장의 의미를 나타내고, 나머지 토큰 출력은 각 단어의 문맥 표현을 나타낸다.\n",
    "\n",
    "\n",
    "**6. BERT의 변형 모델**\n",
    "1. **DistilBERT:** BERT의 경량화 버전으로, 속도는 빠르지만 성능은 유지.\n",
    "2. **ALBERT:** 매개변수를 공유해 메모리 효율을 높이고 속도를 개선.\n",
    "3. **RoBERTa:** 더 긴 학습과 큰 데이터로 학습한 BERT 변형.\n",
    "4. **TinyBERT:** 모바일 및 임베디드 환경을 위한 경량화 모델.\n",
    "5. **SpanBERT:** Span-level 예측을 통해 문맥 이해를 강화.\n",
    "6. **Electra:** Mask 대신 토큰을 대체하여 학습 효율을 높임."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 7320,
     "status": "ok",
     "timestamp": 1750642301909,
     "user": {
      "displayName": "sh qkel",
      "userId": "12967633263148061954"
     },
     "user_tz": -540
    },
    "id": "LIadvRY9W_V9"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2vxDWhboadS5"
   },
   "source": [
    "## Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 16006,
     "status": "ok",
     "timestamp": 1750642385625,
     "user": {
      "displayName": "sh qkel",
      "userId": "12967633263148061954"
     },
     "user_tz": -540
    },
    "id": "PFgNVtNDanEl"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install transformers -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 326,
     "referenced_widgets": [
      "177d073aaab54b598f9c489a30d39abe",
      "b33c245e8ebe449f97c01636c8ef2cfe",
      "8a2fc57982b34f9388a904c79cd7cc27",
      "a665986a0c82456ea4a10d5046d04026",
      "7b70b69b0faa42b3ae179e434525e24f",
      "ef60c2242df7429da24c3205cec86b57",
      "0627ef2eafea4de1aef7ee869f33a5cb",
      "9c9e2ecb7d0941f7892a61d88c44fdda",
      "e4711d823e6a4120b6382f1e500c884a",
      "bf9c1046d9f64f38b18a37c7cd9859e9",
      "a1d02c5ab08d432692769482a957673f",
      "ff77e597dad74c25918c9688b0b7ce7f",
      "0fe4f397f7374f65ac283642a4f380ae",
      "d4952132c5ff46379ad8322a01315f03",
      "30f98dd86ea6400b93e242c47f7e493e",
      "fdefe7cde662492eb10e85756ae9aadd",
      "f2d8dd62c8454450a9be888a3b5be3f3",
      "41885fd737194194bb41b782d52a7352",
      "59da91aa403e40259b756c58776f57d2",
      "7a71ab9b883e444eb7b7dc6e9da856b7",
      "8a007941006448258815f70ab525c00e",
      "9c262dd3fa284a6592ce1921543ff8d6",
      "0dd00de6540c4a329d58799faa7c7cd6",
      "6c65d77140c04e0a9899d4fc581aa4cb",
      "2b549425443649cebea28009deb6b817",
      "a60aa50155f24854951f250b1cab2aa6",
      "4a9b30ac015a47f2927b480ae98c10d7",
      "2cadfa67d3164a4197b0cc14a37b425b",
      "4a3abf95243f41aaa23f99ed25ba7952",
      "38971652d82d497f95b633261950bb47",
      "987bc1e3b9824c418a9729e8692331b6",
      "ec48a6d3fe2a4c799caa9ca306b1382f",
      "dff1be3b69ac4581bb711640dbae7df9",
      "633f3f31e07f42ee835eab95a19035b8",
      "34afab00ac364b1f9eb0a33edca94820",
      "0a07a8c66b1d4a1392f6b7947ff455bb",
      "595d1242a3e24efcb602c748cc8dab60",
      "a16bb3a93a03466fa222835817e19699",
      "e28d9a31b0bf466fb04d7d3e157eb471",
      "a079cc8307ec4069bfb5df2d1c91c413",
      "72d5fdc4cecd4ceaada9ea6fbdb7febf",
      "4a1a8bda33bb4cfe8e536e2b03479d5f",
      "eb32c8e880c5452b8420ba9f818c8be2",
      "3b1f0b006c6243a6a13940d0ae5bedd1"
     ]
    },
    "executionInfo": {
     "elapsed": 4414,
     "status": "ok",
     "timestamp": 1750642427961,
     "user": {
      "displayName": "sh qkel",
      "userId": "12967633263148061954"
     },
     "user_tz": -540
    },
    "id": "ujdYoHtLaaUE",
    "outputId": "1212c4ce-38c4-4999-b1b8-5e7809ee706b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Playdata\\nlp\\nlp_venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertTokenizer(name_or_path='bert-base-uncased', vocab_size=30522, model_max_length=512, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True, added_tokens_decoder={\n",
       "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "model_name = 'bert-base-uncased'\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)  # 해당 모델의 토크나이저(VOCAB/규칙) 로드\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 45,
     "status": "ok",
     "timestamp": 1750642991071,
     "user": {
      "displayName": "sh qkel",
      "userId": "12967633263148061954"
     },
     "user_tz": -540
    },
    "id": "qPYe1bOzclh8",
    "outputId": "eeef36a5-ad87-4bbd-d614-6a213ab8eec6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[101, 2182, 2003, 1996, 6251, 1045, 2215, 7861, 8270, 4667, 2005, 1012, 102]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenizer.encode() -> input_ids\n",
    "text = 'Here is the sentence I want embedding for.'\n",
    "tokenizer.encode(text)  # 토큰화 ([CLS] 문장 -> 정수 ID [SEP] 리스트)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1750643041119,
     "user": {
      "displayName": "sh qkel",
      "userId": "12967633263148061954"
     },
     "user_tz": -540
    },
    "id": "tElBxVKMdIqd",
    "outputId": "d8764c3e-03a8-4273-a123-d9bf6f473b2d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['here', 'is', 'the', 'sentence', 'i', 'want', 'em', '##bed', '##ding', 'for', '.']\n"
     ]
    }
   ],
   "source": [
    "# tokenizer.tokenize() -> tokens\n",
    "print(tokenizer.tokenize(text))  # 문장을 WordPiece 토큰 리스트로 분리해 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1750643111660,
     "user": {
      "displayName": "sh qkel",
      "userId": "12967633263148061954"
     },
     "user_tz": -540
    },
    "id": "sM4uPGBwco-R",
    "outputId": "ceccb28d-e19a-403c-c682-c64f3c9f5725"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 2182, 2003, 1996, 6251, 1045, 2215, 7861, 8270, 4667, 2005, 1012, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenizer() -> {input_ids, attention_mask, token_type_ids}\n",
    "tokenizer(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tgoO6BKkeIym"
   },
   "source": [
    "## Masked LM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 569,
     "status": "ok",
     "timestamp": 1750647697290,
     "user": {
      "displayName": "sh qkel",
      "userId": "12967633263148061954"
     },
     "user_tz": -540
    },
    "id": "LMnnk4CVeMUp",
    "outputId": "eaa1d2a5-11e6-4360-b373-c6529cdfd4c0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForMaskedLM(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (cls): BertOnlyMLMHead(\n",
       "    (predictions): BertLMPredictionHead(\n",
       "      (transform): BertPredictionHeadTransform(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (transform_act_fn): GELUActivation()\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (decoder): Linear(in_features=768, out_features=30522, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertForMaskedLM\n",
    "\n",
    "model_name = 'bert-base-uncased'\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = BertForMaskedLM.from_pretrained(model_name)   # Masked LM 헤드가 포함된 BERT 모델 로드 \n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1750647697305,
     "user": {
      "displayName": "sh qkel",
      "userId": "12967633263148061954"
     },
     "user_tz": -540
    },
    "id": "QOojdJFnho5h",
    "outputId": "84fc1abe-93fb-4253-8492-1fe17873297f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['soccer', 'is', 'a', 'really', 'fun', '[MASK]', '.']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 101, 4715, 2003, 1037, 2428, 4569,  103, 1012,  102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 토큰처리 - 모델입력 -> mask 토큰 추론\n",
    "text = 'Soccer is a really fun [MASK].'\n",
    "\n",
    "tokens = tokenizer.tokenize(text)  # 토큰 리스트론 분해\n",
    "print(tokens)\n",
    "inputs = tokenizer(text, return_tensors='pt') # 모델 입력용 텐서 생성 : pt(pytorch tensor)\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1750647698020,
     "user": {
      "displayName": "sh qkel",
      "userId": "12967633263148061954"
     },
     "user_tz": -540
    },
    "id": "s5-DzlBgiJ8w",
    "outputId": "e309cfd3-dd38-4463-dd03-6ac89b619370"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls:  101\n",
      "sep:  102\n",
      "mask:  103\n"
     ]
    }
   ],
   "source": [
    "# special token 확인\n",
    "print('cls: ', tokenizer.cls_token_id)\n",
    "print('sep: ', tokenizer.sep_token_id)\n",
    "print('mask: ', tokenizer.mask_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 131,
     "status": "ok",
     "timestamp": 1750647828011,
     "user": {
      "displayName": "sh qkel",
      "userId": "12967633263148061954"
     },
     "user_tz": -540
    },
    "id": "P7Tglby4ifnU",
    "outputId": "af53c652-e8cf-4224-92b1-fcda88b2a21e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MaskedLMOutput(loss=None, logits=tensor([[[ -6.8100,  -6.7592,  -6.7455,  ...,  -6.1253,  -5.9923,  -4.0501],\n",
       "         [ -5.6092,  -5.9443,  -5.7752,  ...,  -4.8540,  -5.2307,  -2.8161],\n",
       "         [-11.0772, -10.7695, -10.7907,  ...,  -9.9140,  -7.9280,  -8.7580],\n",
       "         ...,\n",
       "         [ -8.0383,  -8.1772,  -8.0259,  ...,  -8.6722,  -6.6941,  -8.8274],\n",
       "         [-13.4006, -13.3164, -13.4020,  ..., -11.5507, -11.1491,  -8.4797],\n",
       "         [-13.4999, -13.6630, -13.3619,  ..., -13.1450, -12.0269,  -9.0877]]],\n",
       "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = model(**inputs)\n",
    "output # logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1750644727365,
     "user": {
      "displayName": "sh qkel",
      "userId": "12967633263148061954"
     },
     "user_tz": -540
    },
    "id": "AdCi5GdXjIU9",
    "outputId": "c5607db5-050c-45b5-cbba-cef6db8a8132"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "# pipeline\n",
    "from transformers import FillMaskPipeline  # [MASK] 채우기 전용 파이프라인 클래스\n",
    "\n",
    "pipe = FillMaskPipeline(model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 106,
     "status": "ok",
     "timestamp": 1750644728459,
     "user": {
      "displayName": "sh qkel",
      "userId": "12967633263148061954"
     },
     "user_tz": -540
    },
    "id": "F-wCUDpIjcbP",
    "outputId": "78ac86a1-d2ac-4d02-9251-44805a1ef7ae"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.7672328352928162,\n",
       "  'token': 4368,\n",
       "  'token_str': 'sport',\n",
       "  'sequence': 'soccer is a really fun sport.'},\n",
       " {'score': 0.16400203108787537,\n",
       "  'token': 2208,\n",
       "  'token_str': 'game',\n",
       "  'sequence': 'soccer is a really fun game.'},\n",
       " {'score': 0.0157049261033535,\n",
       "  'token': 2518,\n",
       "  'token_str': 'thing',\n",
       "  'sequence': 'soccer is a really fun thing.'},\n",
       " {'score': 0.0071001434698700905,\n",
       "  'token': 2154,\n",
       "  'token_str': 'day',\n",
       "  'sequence': 'soccer is a really fun day.'},\n",
       " {'score': 0.0061270310543477535,\n",
       "  'token': 4023,\n",
       "  'token_str': 'activity',\n",
       "  'sequence': 'soccer is a really fun activity.'}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe(text)  # text 문장의 [MASK]를 채울 후보 단어 (top-k : default 5) 예측 결과 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 191,
     "status": "ok",
     "timestamp": 1750644782380,
     "user": {
      "displayName": "sh qkel",
      "userId": "12967633263148061954"
     },
     "user_tz": -540
    },
    "id": "-QrOfkxkjqFJ",
    "outputId": "95ee14b5-868d-49c9-e363-fa5558d585e3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.3044922351837158,\n",
       "  'token': 2147,\n",
       "  'token_str': 'work',\n",
       "  'sequence': 'i went to work this morning.'},\n",
       " {'score': 0.25700798630714417,\n",
       "  'token': 2793,\n",
       "  'token_str': 'bed',\n",
       "  'sequence': 'i went to bed this morning.'},\n",
       " {'score': 0.08158311247825623,\n",
       "  'token': 2082,\n",
       "  'token_str': 'school',\n",
       "  'sequence': 'i went to school this morning.'},\n",
       " {'score': 0.07317688316106796,\n",
       "  'token': 3637,\n",
       "  'token_str': 'sleep',\n",
       "  'sequence': 'i went to sleep this morning.'},\n",
       " {'score': 0.06206965819001198,\n",
       "  'token': 2465,\n",
       "  'token_str': 'class',\n",
       "  'sequence': 'i went to class this morning.'}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe(\"I went to [MASK] this morning.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "73jC7v-vkLsq"
   },
   "source": [
    "## AutoTokenizer/AutoModel\n",
    "Hugging Face Transformers 라이브러리에서 사전학습(pretrained)된 다양한 NLP 모델을 쉽게 불러와 사용할 수 있도록 도와주는 자동화 클래스이다.\n",
    "\n",
    "반드시 같은 모델 이름을 사용하여 토크나이저와 모델을 로드해야 한다. 서로 다른 모델의 토크나이저와 모델을 함께 쓰면 입력 형식이 달라져 결과가 이상해질 수 있다.\n",
    "\n",
    "### AutoTokenizer\n",
    "아래 표는 Hugging Face Transformers에서 AutoTokenizer가 각 모델별로 내부적으로 어떤 구체적인 토크나이저 클래스를 사용하는지 정리한 것이다. 이 표를 참고하면, AutoTokenizer를 사용할 때 실제로 어떤 토크나이저가 인스턴스화되는지 쉽게 알 수 있다.\n",
    "\n",
    "| 모델명(키워드)      | 실제 토크나이저 클래스                 |\n",
    "|--------------------|--------------------------------------|\n",
    "| bert               | BertTokenizer, BertTokenizerFast      |\n",
    "| roberta            | RobertaTokenizer, RobertaTokenizerFast|\n",
    "| gpt2               | GPT2Tokenizer, GPT2TokenizerFast      |\n",
    "| albert             | AlbertTokenizer, AlbertTokenizerFast  |\n",
    "| distilbert         | DistilBertTokenizer, DistilBertTokenizerFast |\n",
    "| electra            | ElectraTokenizer, ElectraTokenizerFast|\n",
    "| xlnet              | XLNetTokenizer                        |\n",
    "| bart               | BartTokenizer, BartTokenizerFast      |\n",
    "| bloom              | BloomTokenizerFast                    |\n",
    "| deberta            | DebertaTokenizer, DebertaTokenizerFast|\n",
    "| deberta-v2         | DebertaV2Tokenizer, DebertaV2TokenizerFast|\n",
    "| camembert          | CamembertTokenizer, CamembertTokenizerFast|\n",
    "| t5                 | T5Tokenizer                           |\n",
    "| byT5               | ByT5Tokenizer                         |\n",
    "| ctrl               | CTRLTokenizer                         |\n",
    "| blenderbot         | BlenderbotTokenizer, BlenderbotTokenizerFast|\n",
    "| blenderbot-small   | BlenderbotSmallTokenizer              |\n",
    "| pegasus            | PegasusTokenizer, PegasusTokenizerFast|\n",
    "| bigbird            | BigBirdTokenizer, BigBirdTokenizerFast|\n",
    "| codegen            | CodeGenTokenizer, CodeGenTokenizerFast|\n",
    "| llama              | LlamaTokenizer, LlamaTokenizerFast    |\n",
    "| clip               | CLIPTokenizer, CLIPTokenizerFast      |\n",
    "| wav2vec2           | Wav2Vec2CTCTokenizer                  |\n",
    "| canine             | CanineTokenizer                       |\n",
    "\n",
    "- \"Fast\"가 붙은 클래스는 Rust 기반의 빠른 토크나이저 구현체이며, 일반적으로 AutoTokenizer는 가능한 경우 Fast 버전을 우선 사용한다.\n",
    "- 모델 이름에 따라 자동으로 해당 토크나이저가 선택된다. 예를 들어, \"bert-base-uncased\" 모델을 사용하면 BertTokenizer 또는 BertTokenizerFast가 자동으로 로드된다.\n",
    "\n",
    "\n",
    "### AutoModel\n",
    "\n",
    "| **AutoModel 계열**                          | **구체화된 클래스 예시**                                  | **출력 구조**                           | **주요 용도**                          |\n",
    "|---------------------------------------------|----------------------------------------------------------|-----------------------------------------|----------------------------------------|\n",
    "| AutoModel                                   | BertModel, RobertaModel, DistilBertModel, AlbertModel    | 임베딩(은닉 상태)                        | 특징 추출, 커스텀 태스크                |\n",
    "| AutoModelForMaskedLM                        | BertForMaskedLM, RobertaForMaskedLM                      | 임베딩 + MLM 헤드                        | 마스킹된 단어 예측                     |\n",
    "| AutoModelForSequenceClassification          | BertForSequenceClassification, RobertaForSequenceClassification, DistilBertForSequenceClassification, AlbertForSequenceClassification, XLNetForSequenceClassification | 임베딩 + 분류 헤드                      | 문장/문서 분류, 감정 분석              |\n",
    "| AutoModelForTokenClassification             | BertForTokenClassification, RobertaForTokenClassification, DistilBertForTokenClassification, AlbertForTokenClassification | 임베딩 + 토큰 분류 헤드                  | 개체명 인식(NER), POS 태깅             |\n",
    "| AutoModelForQuestionAnswering               | BertForQuestionAnswering, RobertaForQuestionAnswering, DistilBertForQuestionAnswering, AlbertForQuestionAnswering, XLNetForQuestionAnswering | 임베딩 + QA 헤드                        | 질의응답(문서 내 정답 위치)            |\n",
    "| AutoModelForNextSentencePrediction          | BertForNextSentencePrediction                            | 임베딩 + NSP 헤드                        | 문장 간 관계 추론(NSP)                 |\n",
    "| AutoModelForMultipleChoice                  | BertForMultipleChoice, RobertaForMultipleChoice, XLNetForMultipleChoice | 임베딩 + MC 헤드                         | 문맥 기반 질문 답변(Multiple Choice QA)|\n",
    "| AutoModelForCausalLM                        | GPT2LMHeadModel, BertLMHeadModel, RobertaForCausalLM, XLNetLMHeadModel | 임베딩 + 언어 생성 헤드                  | 텍스트 생성, 언어 모델링               |\n",
    "| AutoModelForSeq2SeqLM                       | BartForConditionalGeneration, MarianMTModel, T5ForConditionalGeneration, PegasusForConditionalGeneration | 인코더-디코더 구조                       | 번역, 요약, 질문 생성                  |\n",
    "| AutoModelForImageClassification             | CLIPModel, ViTForImageClassification                     | 이미지 임베딩 + 분류 헤드                 | 이미지 분류, 이미지-텍스트 매칭        |\n",
    "| AutoModelForVision2Seq                      | BlipForConditionalGeneration, GitForCausalLM             | 이미지 인코더 + 텍스트 디코더             | 이미지 캡셔닝, 멀티모달 생성           |\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 715,
     "status": "ok",
     "timestamp": 1750644968672,
     "user": {
      "displayName": "sh qkel",
      "userId": "12967633263148061954"
     },
     "user_tz": -540
    },
    "id": "fAptFwwUkOwm",
    "outputId": "802c0045-c120-43c3-f009-e6a899b56691"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertTokenizerFast\n",
      "BertForMaskedLM\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "\n",
    "model_name = 'bert-base-uncased'  # 사용할 사전학습 모델 이름\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)     # 모델에 맞는 토크나이저 자동 로드\n",
    "model = AutoModelForMaskedLM.from_pretrained(model_name)  # 모델에 맞는 MaskedLM모델 자동 로드\n",
    "\n",
    "print(tokenizer.__class__.__name__)  # 실제 로드된 토크나이저 클래스 이름\n",
    "print(model.__class__.__name__)      # 실제 로드된 모델 클래스 이름"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uNuGD7oxlTQu"
   },
   "source": [
    "## Next Sentence Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 416,
     "status": "ok",
     "timestamp": 1750645303051,
     "user": {
      "displayName": "sh qkel",
      "userId": "12967633263148061954"
     },
     "user_tz": -540
    },
    "id": "0vOMWB5OlZBr"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertTokenizer\n",
      "BertForNextSentencePrediction\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertForNextSentencePrediction\n",
    "\n",
    "model_name = 'bert-base-uncased'\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = BertForNextSentencePrediction.from_pretrained(model_name)    # NSP 헤드가 포함된 BERT 모델 로드\n",
    "\n",
    "print(tokenizer.__class__.__name__)  # 실제 로드된 토크나이저 클래스 이름\n",
    "print(model.__class__.__name__)      # 실제 로드된 모델 클래스 이름"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 357,
     "status": "ok",
     "timestamp": 1750645370216,
     "user": {
      "displayName": "sh qkel",
      "userId": "12967633263148061954"
     },
     "user_tz": -540
    },
    "id": "j2Oxwn1ll345"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertTokenizerFast\n",
      "BertForNextSentencePrediction\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForNextSentencePrediction\n",
    "\n",
    "model_name = 'bert-base-uncased'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForNextSentencePrediction.from_pretrained(model_name)\n",
    "\n",
    "print(tokenizer.__class__.__name__)  # 실제 로드된 토크나이저 클래스 이름\n",
    "print(model.__class__.__name__)      # 실제 로드된 모델 클래스 이름"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1750645527843,
     "user": {
      "displayName": "sh qkel",
      "userId": "12967633263148061954"
     },
     "user_tz": -540
    },
    "id": "JLKP6UT-mKWZ",
    "outputId": "2258460f-66c3-43d4-9c5c-cceff0591f50"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  1999,  3304,  1010, 10733,  2366,  1999,  5337, 10906,  1010,\n",
       "          2107,  2004,  2012,  1037,  4825,  1010,  2003,  3591,  4895, 14540,\n",
       "          6610,  2094,  1012,   102, 10733,  2003,  8828,  2007,  1996,  2224,\n",
       "          1997,  1037,  5442,  1998,  9292,  1012,  1999, 10017, 10906,  1010,\n",
       "          2174,  1010,  2009,  2003,  3013,  2046, 17632,  2015,  2000,  2022,\n",
       "          8828,  2096,  2218,  1999,  1996,  2192,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence1 = \"In Italy, pizza served in formal settings, such as at a restaurant, is presented unsliced.\"\n",
    "sentence2 = \"pizza is eaten with the use of a knife and fork. In casual settings, however, it is cut into wedges to be eaten while held in the hand.\"\n",
    "\n",
    "inputs = tokenizer(sentence1, sentence2, return_tensors='pt')  # 두 문장을 한 쌍으로 인코딩 ([CLS] sentence1 [SEP] sentence2 [SEP])\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 163
    },
    "executionInfo": {
     "elapsed": 75,
     "status": "ok",
     "timestamp": 1750645924083,
     "user": {
      "displayName": "sh qkel",
      "userId": "12967633263148061954"
     },
     "user_tz": -540
    },
    "id": "lQeplxvsnCsY",
    "outputId": "a829fbc2-3e75-4645-da09-d517572961f3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]',\n",
       " 'in',\n",
       " 'italy',\n",
       " ',',\n",
       " 'pizza',\n",
       " 'served',\n",
       " 'in',\n",
       " 'formal',\n",
       " 'settings',\n",
       " ',',\n",
       " 'such',\n",
       " 'as',\n",
       " 'at',\n",
       " 'a',\n",
       " 'restaurant',\n",
       " ',',\n",
       " 'is',\n",
       " 'presented',\n",
       " 'un',\n",
       " '##sl',\n",
       " '##ice',\n",
       " '##d',\n",
       " '.',\n",
       " '[SEP]',\n",
       " 'pizza',\n",
       " 'is',\n",
       " 'eaten',\n",
       " 'with',\n",
       " 'the',\n",
       " 'use',\n",
       " 'of',\n",
       " 'a',\n",
       " 'knife',\n",
       " 'and',\n",
       " 'fork',\n",
       " '.',\n",
       " 'in',\n",
       " 'casual',\n",
       " 'settings',\n",
       " ',',\n",
       " 'however',\n",
       " ',',\n",
       " 'it',\n",
       " 'is',\n",
       " 'cut',\n",
       " 'into',\n",
       " 'wedge',\n",
       " '##s',\n",
       " 'to',\n",
       " 'be',\n",
       " 'eaten',\n",
       " 'while',\n",
       " 'held',\n",
       " 'in',\n",
       " 'the',\n",
       " 'hand',\n",
       " '.',\n",
       " '[SEP]']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "token_sent1 = tokenizer.tokenize(sentence1)  # 문장1을 WordPiece 토큰으로 분해\n",
    "token_sent2 = tokenizer.tokenize(sentence2)  # 문장2을 WordPiece 토큰으로 분해\n",
    "tokens = ['[CLS]'] + token_sent1 + ['[SEP]'] + token_sent2 + ['[SEP]']\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 58])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs['input_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs['token_type_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tokens</th>\n",
       "      <td>[CLS]</td>\n",
       "      <td>in</td>\n",
       "      <td>italy</td>\n",
       "      <td>,</td>\n",
       "      <td>pizza</td>\n",
       "      <td>served</td>\n",
       "      <td>in</td>\n",
       "      <td>formal</td>\n",
       "      <td>settings</td>\n",
       "      <td>,</td>\n",
       "      <td>such</td>\n",
       "      <td>as</td>\n",
       "      <td>at</td>\n",
       "      <td>a</td>\n",
       "      <td>restaurant</td>\n",
       "      <td>,</td>\n",
       "      <td>is</td>\n",
       "      <td>presented</td>\n",
       "      <td>un</td>\n",
       "      <td>##sl</td>\n",
       "      <td>##ice</td>\n",
       "      <td>##d</td>\n",
       "      <td>.</td>\n",
       "      <td>[SEP]</td>\n",
       "      <td>pizza</td>\n",
       "      <td>is</td>\n",
       "      <td>eaten</td>\n",
       "      <td>with</td>\n",
       "      <td>the</td>\n",
       "      <td>use</td>\n",
       "      <td>of</td>\n",
       "      <td>a</td>\n",
       "      <td>knife</td>\n",
       "      <td>and</td>\n",
       "      <td>fork</td>\n",
       "      <td>.</td>\n",
       "      <td>in</td>\n",
       "      <td>casual</td>\n",
       "      <td>settings</td>\n",
       "      <td>,</td>\n",
       "      <td>however</td>\n",
       "      <td>,</td>\n",
       "      <td>it</td>\n",
       "      <td>is</td>\n",
       "      <td>cut</td>\n",
       "      <td>into</td>\n",
       "      <td>wedge</td>\n",
       "      <td>##s</td>\n",
       "      <td>to</td>\n",
       "      <td>be</td>\n",
       "      <td>eaten</td>\n",
       "      <td>while</td>\n",
       "      <td>held</td>\n",
       "      <td>in</td>\n",
       "      <td>the</td>\n",
       "      <td>hand</td>\n",
       "      <td>.</td>\n",
       "      <td>[SEP]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>input_ids</th>\n",
       "      <td>101</td>\n",
       "      <td>1999</td>\n",
       "      <td>3304</td>\n",
       "      <td>1010</td>\n",
       "      <td>10733</td>\n",
       "      <td>2366</td>\n",
       "      <td>1999</td>\n",
       "      <td>5337</td>\n",
       "      <td>10906</td>\n",
       "      <td>1010</td>\n",
       "      <td>2107</td>\n",
       "      <td>2004</td>\n",
       "      <td>2012</td>\n",
       "      <td>1037</td>\n",
       "      <td>4825</td>\n",
       "      <td>1010</td>\n",
       "      <td>2003</td>\n",
       "      <td>3591</td>\n",
       "      <td>4895</td>\n",
       "      <td>14540</td>\n",
       "      <td>6610</td>\n",
       "      <td>2094</td>\n",
       "      <td>1012</td>\n",
       "      <td>102</td>\n",
       "      <td>10733</td>\n",
       "      <td>2003</td>\n",
       "      <td>8828</td>\n",
       "      <td>2007</td>\n",
       "      <td>1996</td>\n",
       "      <td>2224</td>\n",
       "      <td>1997</td>\n",
       "      <td>1037</td>\n",
       "      <td>5442</td>\n",
       "      <td>1998</td>\n",
       "      <td>9292</td>\n",
       "      <td>1012</td>\n",
       "      <td>1999</td>\n",
       "      <td>10017</td>\n",
       "      <td>10906</td>\n",
       "      <td>1010</td>\n",
       "      <td>2174</td>\n",
       "      <td>1010</td>\n",
       "      <td>2009</td>\n",
       "      <td>2003</td>\n",
       "      <td>3013</td>\n",
       "      <td>2046</td>\n",
       "      <td>17632</td>\n",
       "      <td>2015</td>\n",
       "      <td>2000</td>\n",
       "      <td>2022</td>\n",
       "      <td>8828</td>\n",
       "      <td>2096</td>\n",
       "      <td>2218</td>\n",
       "      <td>1999</td>\n",
       "      <td>1996</td>\n",
       "      <td>2192</td>\n",
       "      <td>1012</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token_type_ids</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0     1      2     3      4       5     6       7   \\\n",
       "tokens          [CLS]    in  italy     ,  pizza  served    in  formal   \n",
       "input_ids         101  1999   3304  1010  10733    2366  1999    5337   \n",
       "token_type_ids      0     0      0     0      0       0     0       0   \n",
       "\n",
       "                      8     9     10    11    12    13          14    15  \\\n",
       "tokens          settings     ,  such    as    at     a  restaurant     ,   \n",
       "input_ids          10906  1010  2107  2004  2012  1037        4825  1010   \n",
       "token_type_ids         0     0     0     0     0     0           0     0   \n",
       "\n",
       "                  16         17    18     19     20    21    22     23     24  \\\n",
       "tokens            is  presented    un   ##sl  ##ice   ##d     .  [SEP]  pizza   \n",
       "input_ids       2003       3591  4895  14540   6610  2094  1012    102  10733   \n",
       "token_type_ids     0          0     0      0      0     0     0      0      1   \n",
       "\n",
       "                  25     26    27    28    29    30    31     32    33    34  \\\n",
       "tokens            is  eaten  with   the   use    of     a  knife   and  fork   \n",
       "input_ids       2003   8828  2007  1996  2224  1997  1037   5442  1998  9292   \n",
       "token_type_ids     1      1     1     1     1     1     1      1     1     1   \n",
       "\n",
       "                  35    36      37        38    39       40    41    42    43  \\\n",
       "tokens             .    in  casual  settings     ,  however     ,    it    is   \n",
       "input_ids       1012  1999   10017     10906  1010     2174  1010  2009  2003   \n",
       "token_type_ids     1     1       1         1     1        1     1     1     1   \n",
       "\n",
       "                  44    45     46    47    48    49     50     51    52    53  \\\n",
       "tokens           cut  into  wedge   ##s    to    be  eaten  while  held    in   \n",
       "input_ids       3013  2046  17632  2015  2000  2022   8828   2096  2218  1999   \n",
       "token_type_ids     1     1      1     1     1     1      1      1     1     1   \n",
       "\n",
       "                  54    55    56     57  \n",
       "tokens           the  hand     .  [SEP]  \n",
       "input_ids       1996  2192  1012    102  \n",
       "token_type_ids     1     1     1      1  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None) # 컬럼생략 안함(전부 출력)\n",
    "\n",
    "pd.DataFrame([\n",
    "    tokens,                                        # 사람이 읽는 토크 시퀀스\n",
    "    inputs['input_ids'].squeeze(0).numpy(),        # (1, L) -> (L,) 줄이고 ID 배열 표시\n",
    "    inputs['token_type_ids'].squeeze(0).numpy(),   # (1, L) -> (L,) 줄이고 문장 구분 ID 표시 (0=A, 1=B)\n",
    "], index=['tokens', 'input_ids', 'token_type_ids'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 284,
     "status": "ok",
     "timestamp": 1750646253569,
     "user": {
      "displayName": "sh qkel",
      "userId": "12967633263148061954"
     },
     "user_tz": -540
    },
    "id": "K3URl3X7osmd",
    "outputId": "d05fe9b1-7b67-451d-cff2-0134ee0c572e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NextSentencePredictorOutput(loss=None, logits=tensor([[-3.0729,  5.9056]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "tensor([[-3.0729,  5.9056]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.2606e-04, 9.9987e-01]], grad_fn=<SoftmaxBackward0>)\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# tokenizer - model 직접 사용\n",
    "output = model(**inputs)    # NSP forward 수행 -> logits 포함한 출력 객체 반환\n",
    "print(output)\n",
    "print(output[0])\n",
    "\n",
    "prob = F.softmax(output[0], dim=-1)  # logits(2클래스) -> 확률로 변환\n",
    "print(prob)                          # [IsNext, NotNext] 확률 출력\n",
    "\n",
    "pred = torch.argmax(prob, dim=-1).item()  # 확률이 더 큰 클래스 인덱스 선택\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 554,
     "status": "ok",
     "timestamp": 1750646447139,
     "user": {
      "displayName": "sh qkel",
      "userId": "12967633263148061954"
     },
     "user_tz": -540
    },
    "id": "CdCSWWhrpoJ0",
    "outputId": "f33af1f3-ca3f-47d2-8079-22b4b4c2b64c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-3.0729,  5.9056]], grad_fn=<AddmmBackward0>)\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "sentence3 = \"The sky is blue due to the shorter wavelength of blue light.\"\n",
    "\n",
    "inputs = tokenizer(sentence1, sentence3, return_tensors='pt')\n",
    "output = model(**inputs)\n",
    "print(output[0])\n",
    "\n",
    "prob = F.softmax(output[0], dim=-1)\n",
    "\n",
    "pred = torch.argmax(prob, dim=-1).item()\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IsNext=1.0000 | pizza is eaten with the use of a knife and fork. In casual s...\n",
      "IsNext=1.0000 | Pizza is one of the most popular foods in the world....\n",
      "IsNext=0.0001 | The sky is blue due to the shorter wavelength of blue light....\n",
      "IsNext=0.0000 | I enjoy playing football on weekends....\n"
     ]
    }
   ],
   "source": [
    "# NSP로 문장2 후보들 중 \"가장 이어질만한 문장\" 순위 매기기\n",
    "candidates = [\n",
    "    sentence2,\n",
    "    sentence3,\n",
    "    \"Pizza is one of the most popular foods in the world.\",\n",
    "    \"I enjoy playing football on weekends.\"\n",
    "]\n",
    "\n",
    "scores = []                                                # (IsNext, 후보문장) 저장 리스트\n",
    "for s2 in candidates:\n",
    "    inp = tokenizer(sentence1, s2, return_tensors='pt')\n",
    "    out = model(**inp)\n",
    "    prob = F.softmax(out.logits, dim=-1).squeeze(0)        # logits(1, 2) -> 확률(2, ) 변환\n",
    "    isnext = float(prob[0])                                # IsNext(이어짐) 확률만 추출\n",
    "    scores.append((isnext, s2))\n",
    "\n",
    "scores.sort(reverse=True, key=lambda x: x[0])                            # IsNext 확률 낮은 순부터 정렬\n",
    "for p, s2 in scores:\n",
    "    print(f\"IsNext={p:.4f} | {s2[:60]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMtrg1u8AunXmeqDgKorNv9",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "nlp_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0627ef2eafea4de1aef7ee869f33a5cb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0a07a8c66b1d4a1392f6b7947ff455bb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_72d5fdc4cecd4ceaada9ea6fbdb7febf",
      "max": 570,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4a1a8bda33bb4cfe8e536e2b03479d5f",
      "value": 570
     }
    },
    "0dd00de6540c4a329d58799faa7c7cd6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6c65d77140c04e0a9899d4fc581aa4cb",
       "IPY_MODEL_2b549425443649cebea28009deb6b817",
       "IPY_MODEL_a60aa50155f24854951f250b1cab2aa6"
      ],
      "layout": "IPY_MODEL_4a9b30ac015a47f2927b480ae98c10d7"
     }
    },
    "0fe4f397f7374f65ac283642a4f380ae": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f2d8dd62c8454450a9be888a3b5be3f3",
      "placeholder": "​",
      "style": "IPY_MODEL_41885fd737194194bb41b782d52a7352",
      "value": "vocab.txt: 100%"
     }
    },
    "177d073aaab54b598f9c489a30d39abe": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b33c245e8ebe449f97c01636c8ef2cfe",
       "IPY_MODEL_8a2fc57982b34f9388a904c79cd7cc27",
       "IPY_MODEL_a665986a0c82456ea4a10d5046d04026"
      ],
      "layout": "IPY_MODEL_7b70b69b0faa42b3ae179e434525e24f"
     }
    },
    "2b549425443649cebea28009deb6b817": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_38971652d82d497f95b633261950bb47",
      "max": 466062,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_987bc1e3b9824c418a9729e8692331b6",
      "value": 466062
     }
    },
    "2cadfa67d3164a4197b0cc14a37b425b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "30f98dd86ea6400b93e242c47f7e493e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8a007941006448258815f70ab525c00e",
      "placeholder": "​",
      "style": "IPY_MODEL_9c262dd3fa284a6592ce1921543ff8d6",
      "value": " 232k/232k [00:00&lt;00:00, 2.36MB/s]"
     }
    },
    "34afab00ac364b1f9eb0a33edca94820": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e28d9a31b0bf466fb04d7d3e157eb471",
      "placeholder": "​",
      "style": "IPY_MODEL_a079cc8307ec4069bfb5df2d1c91c413",
      "value": "config.json: 100%"
     }
    },
    "38971652d82d497f95b633261950bb47": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3b1f0b006c6243a6a13940d0ae5bedd1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "41885fd737194194bb41b782d52a7352": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4a1a8bda33bb4cfe8e536e2b03479d5f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "4a3abf95243f41aaa23f99ed25ba7952": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4a9b30ac015a47f2927b480ae98c10d7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "595d1242a3e24efcb602c748cc8dab60": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_eb32c8e880c5452b8420ba9f818c8be2",
      "placeholder": "​",
      "style": "IPY_MODEL_3b1f0b006c6243a6a13940d0ae5bedd1",
      "value": " 570/570 [00:00&lt;00:00, 10.5kB/s]"
     }
    },
    "59da91aa403e40259b756c58776f57d2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "633f3f31e07f42ee835eab95a19035b8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_34afab00ac364b1f9eb0a33edca94820",
       "IPY_MODEL_0a07a8c66b1d4a1392f6b7947ff455bb",
       "IPY_MODEL_595d1242a3e24efcb602c748cc8dab60"
      ],
      "layout": "IPY_MODEL_a16bb3a93a03466fa222835817e19699"
     }
    },
    "6c65d77140c04e0a9899d4fc581aa4cb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2cadfa67d3164a4197b0cc14a37b425b",
      "placeholder": "​",
      "style": "IPY_MODEL_4a3abf95243f41aaa23f99ed25ba7952",
      "value": "tokenizer.json: 100%"
     }
    },
    "72d5fdc4cecd4ceaada9ea6fbdb7febf": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7a71ab9b883e444eb7b7dc6e9da856b7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "7b70b69b0faa42b3ae179e434525e24f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8a007941006448258815f70ab525c00e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8a2fc57982b34f9388a904c79cd7cc27": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9c9e2ecb7d0941f7892a61d88c44fdda",
      "max": 48,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e4711d823e6a4120b6382f1e500c884a",
      "value": 48
     }
    },
    "987bc1e3b9824c418a9729e8692331b6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "9c262dd3fa284a6592ce1921543ff8d6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9c9e2ecb7d0941f7892a61d88c44fdda": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a079cc8307ec4069bfb5df2d1c91c413": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a16bb3a93a03466fa222835817e19699": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a1d02c5ab08d432692769482a957673f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a60aa50155f24854951f250b1cab2aa6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ec48a6d3fe2a4c799caa9ca306b1382f",
      "placeholder": "​",
      "style": "IPY_MODEL_dff1be3b69ac4581bb711640dbae7df9",
      "value": " 466k/466k [00:00&lt;00:00, 5.56MB/s]"
     }
    },
    "a665986a0c82456ea4a10d5046d04026": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bf9c1046d9f64f38b18a37c7cd9859e9",
      "placeholder": "​",
      "style": "IPY_MODEL_a1d02c5ab08d432692769482a957673f",
      "value": " 48.0/48.0 [00:00&lt;00:00, 437B/s]"
     }
    },
    "b33c245e8ebe449f97c01636c8ef2cfe": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ef60c2242df7429da24c3205cec86b57",
      "placeholder": "​",
      "style": "IPY_MODEL_0627ef2eafea4de1aef7ee869f33a5cb",
      "value": "tokenizer_config.json: 100%"
     }
    },
    "bf9c1046d9f64f38b18a37c7cd9859e9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d4952132c5ff46379ad8322a01315f03": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_59da91aa403e40259b756c58776f57d2",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_7a71ab9b883e444eb7b7dc6e9da856b7",
      "value": 231508
     }
    },
    "dff1be3b69ac4581bb711640dbae7df9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e28d9a31b0bf466fb04d7d3e157eb471": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e4711d823e6a4120b6382f1e500c884a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "eb32c8e880c5452b8420ba9f818c8be2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ec48a6d3fe2a4c799caa9ca306b1382f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ef60c2242df7429da24c3205cec86b57": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f2d8dd62c8454450a9be888a3b5be3f3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fdefe7cde662492eb10e85756ae9aadd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ff77e597dad74c25918c9688b0b7ce7f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0fe4f397f7374f65ac283642a4f380ae",
       "IPY_MODEL_d4952132c5ff46379ad8322a01315f03",
       "IPY_MODEL_30f98dd86ea6400b93e242c47f7e493e"
      ],
      "layout": "IPY_MODEL_fdefe7cde662492eb10e85756ae9aadd"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
