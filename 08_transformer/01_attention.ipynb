{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd0f8532",
   "metadata": {},
   "source": [
    "# Scaled Dot-Product Attention 계산 실습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ae5d3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 x: torch.Size([1, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F \n",
    "\n",
    "# batch_size, seq_len, embedding_dim\n",
    "x =  torch.tensor([[[1.0, 0.0, 1.0, 0.0],\n",
    "                   [0.0, 2.0, 0.0, 2.0],\n",
    "                   [1.0, 1.0, 1.0, 1.0]]]) \n",
    "\n",
    " # 배치, 길이 차원 (1, 3, 4)\n",
    "\n",
    "print(\"입력 x:\", x.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11796e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: torch.Size([1, 3, 4])\n",
      "K: torch.Size([1, 3, 4])\n",
      "V: torch.Size([1, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "# Q, K, V를 생성하는 선형층\n",
    "\n",
    "W_q = nn.Linear(4, 4, bias=False)   # Query 생성용 선형 변환(4 -> 4)\n",
    "W_k = nn.Linear(4, 4, bias=False)   # Key 생성용 선형 변환(4 -> 4)\n",
    "W_v = nn.Linear(4, 4, bias=False)   # Value 생성용 선형 변환(4 -> 4)\n",
    "\n",
    "# Q, K, V\n",
    "Q = W_q(x)                           # x -> Q(배치, 길이 차원)\n",
    "K = W_k(x)                           # x -> K\n",
    "V = W_v(x)                           # x -> V\n",
    "\n",
    "\n",
    "print(\"Q:\" ,Q.shape)\n",
    "print(\"K:\" ,K.shape)\n",
    "print(\"V:\" ,V.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745b94b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attn_scores: torch.Size([1, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "# 1. Q, K 유사도 계산\n",
    "attn_scores = torch.matmul(Q, K.transpose(-2, -1))  # Q*K^T 토큰간 유사도(Score) 계산\n",
    "attn_scores /= Q.size(-1) ** 0.5                    # 차원(d_k)로 나눠 Score 스케일 조정(Softmax 안정화)\n",
    "print(\"attn_scores:\", attn_scores.shape)            # score 행렬 (1, 3, 3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3f230a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attn_weights :  torch.Size([1, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "# 2. attention 분포 (확률)\n",
    "attn_weights = F.softmax(attn_scores, dim=-1)        # 각 토큰이 바라볼 비율을 확률로 변환(행 단위 합 = 1)\n",
    "print(\"attn_weights : \", attn_weights.shape)         # attention 가중치 (1, 3, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73277484",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attn_value : torch.Size([1, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "# 3. V-attention 분포의 가중합\n",
    "output = torch.matmul(attn_weights, V)               # attention 가중치로 V를 가중합해 최종 출력 생성\n",
    "print('attn_value :', output.shape)                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01dbacb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 x  tensor([[[1., 0., 1., 0.],\n",
      "         [0., 2., 0., 2.],\n",
      "         [1., 1., 1., 1.]]])\n",
      "\n",
      "Q  tensor([[[-0.1392,  0.5523,  0.2820,  0.0902],\n",
      "         [ 0.2970,  0.8269, -0.4085,  0.1327],\n",
      "         [ 0.0093,  0.9658,  0.0777,  0.1565]]], grad_fn=<UnsafeViewBackward0>)\n",
      "\n",
      "K  tensor([[[ 0.5735,  0.6561, -0.0016, -0.1080],\n",
      "         [-0.7842, -0.0042, -0.3043, -0.1294],\n",
      "         [ 0.1814,  0.6540, -0.1537, -0.1727]]], grad_fn=<UnsafeViewBackward0>)\n",
      "\n",
      "V  tensor([[[ 0.1540,  0.6550, -0.3631,  0.0075],\n",
      "         [ 0.2296,  1.0156, -1.2490,  0.8316],\n",
      "         [ 0.2688,  1.1628, -0.9876,  0.4233]]], grad_fn=<UnsafeViewBackward0>)\n",
      "\n",
      "attention 분포 : tensor([[[0.3473, 0.3045, 0.3481],\n",
      "         [0.3804, 0.2514, 0.3683],\n",
      "         [0.3705, 0.2641, 0.3654]]], grad_fn=<SoftmaxBackward0>)\n",
      "\n",
      "출력 output : tensor([[[ 0.2170,  0.9416, -0.8503,  0.4032],\n",
      "         [ 0.2153,  0.9327, -0.8158,  0.3677],\n",
      "         [ 0.2159,  0.9358, -0.8253,  0.3770]]], grad_fn=<UnsafeViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Attention 중간 결과(Q/K/V)와 분포, 최종 출력 확인\n",
    "print(\"입력 x \", x)     # 원본 입력값\n",
    "print(\"\\nQ \", Q)        # Query 벡터(선형변환 결과)\n",
    "print(\"\\nK \", K)        # Key 벡터  (선형변환 결과)\n",
    "print(\"\\nV \", V)        # Value 벡터(선형변환 결과)\n",
    "\n",
    "print(\"\\nattention 분포 :\", attn_weights)   # 가중치 : 각 토큰이 다른 토큰을 얼마나 참조하는지(확률 분포)\n",
    "print(\"\\n출력 output :\", output)            # attention 가중합으로 만들어진 최종 출력 텐서"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65351b4a",
   "metadata": {},
   "source": [
    "# Multi-Head-Attention (헤드 분할/결합) 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7267c9ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 x torch.Size([1, 3, 8])\n"
     ]
    }
   ],
   "source": [
    "# batch_size, seq_len, embedding_dim\n",
    "x = torch.tensor([[[1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0],\n",
    "                   [0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0],\n",
    "                   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]]])  # 1, 3, 8\n",
    "\n",
    "print(\"입력 x\", x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dba209c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: torch.Size([1, 3, 8])\n",
      "K: torch.Size([1, 3, 8])\n",
      "V: torch.Size([1, 3, 8])\n"
     ]
    }
   ],
   "source": [
    "B, T, embedding_dim = x.shape           # B, T, E\n",
    "num_head = 4                            # 헤드 개수\n",
    "heading_dim = embedding_dim // num_head # 헤드당 차원 (d_k)\n",
    "\n",
    "W_q = nn.Linear(embedding_dim, embedding_dim, bias=False)   # Query 생성용 선형 변환(8 -> 8)\n",
    "W_k = nn.Linear(embedding_dim, embedding_dim, bias=False)   # Key   생성용 선형 변환\n",
    "W_v = nn.Linear(embedding_dim, embedding_dim, bias=False)   # Value 생성용 선형 변환\n",
    "\n",
    "# Q, K, V\n",
    "Q = W_q(x)                           # (B, T, 8) -> (B, T, 8)\n",
    "K = W_k(x)                           # (B, T, 8) -> (B, T, 8)\n",
    "V = W_v(x)                           # (B, T, 8) -> (B, T, 8)\n",
    "\n",
    "\n",
    "print(\"Q:\" ,Q.shape)\n",
    "print(\"K:\" ,K.shape)\n",
    "print(\"V:\" ,V.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28d4513",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q_head torch.Size([1, 4, 3, 2])\n",
      "K_head torch.Size([1, 4, 3, 2])\n",
      "V_head torch.Size([1, 4, 3, 2])\n"
     ]
    }
   ],
   "source": [
    "# 헤드 분할\n",
    "# B, T, embedding_dim\n",
    "# -> B, T, num_head, heading_dim\n",
    "# -> B, num_head, T, heading_dim\n",
    "\n",
    "Q_head = Q.view(B, T, num_head, heading_dim).transpose(1, 2)    # Q를 헤드별로 쪼개고(num_head) 차원 위치 교환\n",
    "K_head = K.view(B, T, num_head, heading_dim).transpose(1, 2)    # K도 동일하게 헤드 분할\n",
    "V_head = V.view(B, T, num_head, heading_dim).transpose(1, 2)    # V도 동일하게 헤드 분할\n",
    "\n",
    "print(\"Q_head\", Q_head.shape)   # (B, num_head, T, heading_dim)\n",
    "print(\"K_head\", K_head.shape)   # (B, num_head, T, heading_dim)\n",
    "print(\"V_head\", V_head.shape)   # (B, num_head, T, heading_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f09846d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attention_score : torch.Size([1, 4, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "# Q, K 유사도 계산\n",
    "attn_scores = torch.matmul(Q_head, K_head.transpose(-2, -1))    # 각 헤드별로 Q*K^T 계산 (B, num_head, T, T)\n",
    "attn_scores /= embedding_dim ** 0.5                             # 스케일링(defalut) \n",
    "print(\"attention_score :\", attn_scores.shape)                   # score shape 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9dfcfeaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "어텐션 분포 : torch.Size([1, 4, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "# attention 분포 계산\n",
    "attn_weights = F.softmax(attn_scores, dim=-1)   # 마지막 축을 기준으로 softmax -> 확률 분포\n",
    "print(\"어텐션 분포 :\", attn_weights.shape)       # (B, num_head, T, T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1ab2ef76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "출력 어텐션값 : torch.Size([1, 4, 3, 2])\n"
     ]
    }
   ],
   "source": [
    "# V와 가중합 계산\n",
    "output = torch.matmul(attn_weights, V_head)     # 가중합 -> (B, num_head, T, heading_dim)\n",
    "print('출력 어텐션값 :', output.shape)           # 헤드별 출력 shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f82505a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "출력 (헤드결합) :  torch.Size([1, 3, 8])\n"
     ]
    }
   ],
   "source": [
    "# 헤드 결합\n",
    "output = output.transpose(1, 2)                         # (B, num_head, T, d_k) - > (B, T, num_head, d_k)\n",
    "output = output.contiguous().view(B, T, embedding_dim)  # (B, T, num_head*d_k) -> (B, T, d_model)\n",
    "print(\"출력 (헤드결합) : \", output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d7250b",
   "metadata": {},
   "source": [
    "tensor.contiguous() : view() 호출하기 전 메모리의 연속된 상태를 변환"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a107416",
   "metadata": {},
   "source": [
    "- 일반 Attention vs Multi-Head Attention\n",
    "(1) 같은 문장에서도 “관계”는 여러 종류라서  \n",
    "예: “나는 어제 은행에 갔다”  \n",
    "“은행”이 finance인지 river bank인지 문맥으로 판단해야 함  \n",
    "어떤 헤드는 “시간/장소 단서”에  \n",
    "다른 헤드는 “주변 단어 의미”에  \n",
    "또 다른 헤드는 “문장 전역 정보”에 집중하는 식으로 동시에 여러 관계를 잡아냄  \n",
    "\n",
    "\n",
    "(2) 긴 문장/복잡한 문맥에서 더 잘 버팀  \n",
    "싱글 attention은 전역을 다 보긴 하지만 “한 가지 정렬”로만 보니까,  \n",
    "복잡한 의존성이 많아질수록 한 번에 잡기 힘든데  \n",
    "MHA는 여러 헤드가 분산해서 잡아주니 안정적.  \n",
    "\n",
    "(3) 병렬 연산이 잘 맞아서(Transformer의 장점 극대화)  \n",
    "RNN처럼 순차가 아니라 행렬곱 중심이라 GPU에서 효율이 좋고,  \n",
    "MHA는 “여러 attention을 병렬로” 돌려도 구조적으로 잘 맞음.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
